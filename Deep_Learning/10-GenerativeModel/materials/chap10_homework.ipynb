{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第10回講義 宿題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題. 変分オートエンコーダ（VAE）でFasionMNISTの画像を生成せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変分オートエンコーダ（VAE）により, FashionMNISTの画像を生成してみましょう.。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ルール"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 訓練データはx_train、テストデータはx_testで与えられます。\n",
    "- 下のセルで指定されているx_train以外の学習データは使わないでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目標値"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLL（負の対数尤度） 235"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提出方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2つのファイルを提出していただきます。\n",
    "    1. テストデータ（x_test）について、VAEで生成した画像をcsvファイル（ファイル名：submission.csv）として保存し（1画像が1行に対応）、**Homeworkタブからchap10を選択して**提出してください。\n",
    "    2. それに対応するpythonのコードをsubmission_code.pyとして保存し、**Homeworkタブからchap10 (code)を選択して**提出してください。 \n",
    "      - セルに書いたコードを.py形式で保存するためには%%writefileコマンドなどを利用してください（writefileコマンドではファイルの保存のみが行われセル内のpythonコード自体は実行されません。そのため、実際にコードを走らせる際にはwritefileコマンドをコメントアウトしてください）。\n",
    "- なお、採点は1で行い、2はコードの確認用として利用します（成績優秀者はコード内容を公開させていただくかもしれません）。コードの内容を変更した場合は、**1と2の両方を提出し直してください**。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評価について"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 評価は生成画像のテストデータに対するNLL（負の対数尤度）で行います.  $-\\sum_{i=1}^D x_i\\log \\hat{x}_i + (1-x_i)\\log (1-\\hat{x}_i)$\n",
    "- 毎日夜24時にテストデータの一部に対するNLLでLeader Boardを更新します。\n",
    "- 締切日の夜24時にテストデータ全体に対するNLLでLeader Boardを更新します。これを最終的な評価とします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## サンプルコード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 次のセルで指定されているx_trainのみを使って学習させてください.\n",
    "- submission.csvの出力場所は適宜変更してください."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# このデータの読み込み部分は修正しないでください\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_mnist():\n",
    "\n",
    "    # 学習データ\n",
    "    x_train = np.load('../data/x_train.npy')\n",
    "    \n",
    "    # テストデータ\n",
    "    x_test = np.load('../data/x_test.npy')\n",
    "\n",
    "    x_train = (x_train.reshape(-1, 784) / 255).astype(np.float32)\n",
    "    x_test = (x_test.reshape(-1, 784) / 255).astype(np.float32)\n",
    "\n",
    "    return (x_train, x_test)\n",
    "\n",
    "x_train, x_test = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAEの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing submission_code.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile submission_code.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "\n",
    "### define layers ###\n",
    "tf.reset_default_graph()\n",
    "z_dim = 10\n",
    "\n",
    "def tf_log(x):\n",
    "    return tf.log(tf.clip_by_value(x, 1e-10, x))\n",
    "\n",
    "def encoder(x):\n",
    "    with tf.variable_scope('Encoder', reuse=tf.AUTO_REUSE):\n",
    "        h1 = tf.layers.Dense(units=200, activation=tf.nn.relu)(x)\n",
    "        h2 = tf.layers.Dense(units=200, activation=tf.nn.relu)(h1)\n",
    "        mean = tf.layers.Dense(units=z_dim)(h2)\n",
    "        var = tf.layers.Dense(units=z_dim, activation=tf.nn.softplus)(h2)\n",
    "    return mean, var\n",
    "\n",
    "def sampling_z(mean, var):\n",
    "    epsilon = tf.random_normal(shape=tf.shape(mean))\n",
    "    z = mean + tf.sqrt(var) * epsilon\n",
    "    return z\n",
    "\n",
    "def decoder(z):\n",
    "    with tf.variable_scope('Decoder', reuse=tf.AUTO_REUSE):\n",
    "        h3 = tf.layers.Dense(units=200, activation=tf.nn.relu)(z)\n",
    "        h4 = tf.layers.Dense(units=200, activation=tf.nn.relu)(h3)\n",
    "        y = tf.layers.Dense(units=784, activation=tf.nn.sigmoid)(h4)\n",
    "    return y\n",
    "\n",
    "def lower_bound(x):\n",
    "    #Encode\n",
    "    mean, var = encoder(x)\n",
    "    KL = -0.5 * tf.reduce_mean(tf.reduce_sum(1 + tf_log(var) - mean**2 - var, axis=1))\n",
    "    \n",
    "    #Z\n",
    "    z = sampling_z(mean, var)\n",
    "    \n",
    "    #Decode\n",
    "    y = decoder(z)\n",
    "    reconstruction = tf.reduce_mean(tf.reduce_sum(x * tf_log(y) + (1 - x) * tf_log(1 - y), axis=1))\n",
    "    \n",
    "    lower_bound = [-KL, reconstruction]\n",
    "    \n",
    "    return lower_bound\n",
    "\n",
    "\n",
    "### training ###\n",
    "#学習データと検証データに分割\n",
    "x_train, x_valid = train_test_split(x_train, test_size=0.1)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "lower_bound = lower_bound(x)\n",
    "\n",
    "cost = -tf.reduce_sum(lower_bound)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "valid = tf.reduce_sum(lower_bound)\n",
    "\n",
    "batch_size =100\n",
    "\n",
    "n_batches = x_train.shape[0] // batch_size\n",
    "n_epochs = 15\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "for epoch in range(n_epochs):\n",
    "    rng.shuffle(x_train)\n",
    "    lower_bound_all = []\n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        _, lowerbound = sess.run([train, lower_bound], feed_dict={x: x_train[start:end]})\n",
    "        lower_bound_all.append(lowerbound)\n",
    "    lower_bound_all = np.mean(lower_bound_all, axis=0)\n",
    "    lower_bound_valid = sess.run(valid, feed_dict={x: x_valid[0:100]})\n",
    "    print('EPOCH:%d, Train Lower Bound:%lf, (%lf, %lf), Valid Lower Bound:%lf' %\n",
    "          (epoch+1, np.sum(lower_bound_all), lower_bound_all[0], lower_bound_all[1], lower_bound_valid))\n",
    "    \n",
    "    \n",
    "### sampling ###\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "sample_z_func = encoder(x)\n",
    "\n",
    "z = tf.placeholder(tf.float32, [None, z_dim])\n",
    "sample_x_func = decoder(z)\n",
    "\n",
    "# Encode\n",
    "mean, var = sess.run(sample_z_func, feed_dict={x: x_test})\n",
    "sample_z = mean\n",
    "\n",
    "# Decode\n",
    "sample_x = sess.run(sample_x_func, feed_dict={z: sample_z})\n",
    "\n",
    "\n",
    "### to_csv ###\n",
    "with open('submission.csv', 'w') as file:\n",
    "    writer = csv.writer(file, lineterminator='\\n')\n",
    "    writer.writerows(sample_x.reshape(-1, 28*28).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
