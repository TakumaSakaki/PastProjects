{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第9回講義 演習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目次\n",
    "\n",
    "課題1. Recurrent Neural Network (RNN) Encoder-Decoderモデルで英日翻訳\n",
    "1. データセットの読み込みと単語・品詞のID化\n",
    "2. 各層クラスの実装\n",
    "3. 計算グラフ構築 & パラメータの更新設定\n",
    "4. 学習\n",
    "5. 生成\n",
    "\n",
    "課題2. Attentionを用いた機械翻訳モデルの実装\n",
    "1. Attention層の実装\n",
    "2. 計算グラフ構築 & パラメータの更新設定\n",
    "3. 学習\n",
    "4. 生成\n",
    "\n",
    "【補足】機械翻訳の評価について\n",
    "\n",
    "【補足】Beam searchについて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題1. Recurrent Neural Network (RNN) Encoder-Decoderモデルで英日翻訳"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. データセットの読み込みと単語・品詞のID化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はデータセットとして、英文とその日本語対訳がセットになった Tanaka Corpus ( http://www.edrdg.org/wiki/index.php/Tanaka_Corpus ) を使用します。\n",
    "\n",
    "（厳密にはサイズの関係で、Tanaka Corpusの一部を抽出した https://github.com/odashi/small_parallel_enja を使っています。）\n",
    "\n",
    "train.enとtrain.jaの中身は次のようになっています。\n",
    "\n",
    "- train.enの中身 (英語の文)\n",
    "```\n",
    "i can 't tell who will arrive first .\n",
    "many animals have been destroyed by men .\n",
    "i 'm in the tennis club .\n",
    "︙\n",
    "```\n",
    "\n",
    "- train.jaの中身(日本語の文、対訳)\n",
    "```\n",
    "誰 が 一番 に 着 く か 私 に は 分か り ま せ ん 。\n",
    "多く の 動物 が 人間 に よ っ て 滅ぼ さ れ た 。\n",
    "私 は テニス 部員 で す 。\n",
    "︙\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この通り、そのまま読み込むと単語のまま読み込まれます。\n",
    "\n",
    "これでは計算的には扱いづらいので、それぞれの単語を**数字によるIDに置き換え**ましょう。\n",
    "\n",
    "この数値化には、`keras.preprocessing.text`の`Tokenizer`を用います。（割り当ては1からなので、0はpaddingに使用できます。）\n",
    "\n",
    "ここではTokenizerの仕様については深く立ち入りませんので、気になる方は公式ドキュメントをチェックしてください。\n",
    "\n",
    "なお、読み込む際には\n",
    "\n",
    "- 文頭を表す仮想単語（**BOS**, Beginning Of Sentence）として`<s>`\n",
    "\n",
    "- 文末を表す仮想単語（**EOS**, End Of Sentence）として`</s>`\n",
    "    \n",
    "を付加します。\n",
    "\n",
    "参考：https://keras.io/ja/preprocessing/text/#tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, num_words=None):\n",
    "    tokenizer = Tokenizer(num_words, filters=\"\")\n",
    "    whole_texts = []\n",
    "    for line in open(file_path, encoding='utf-8'):\n",
    "        whole_texts.append(\"<s> \" + line.strip() + \" </s>\")\n",
    "        \n",
    "    tokenizer.fit_on_texts(whole_texts)\n",
    "    \n",
    "    return tokenizer.texts_to_sequences(whole_texts), tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 読み込み＆Tokenizerによる数値化\n",
    "pad_index = 0\n",
    "x_train, tokenizer_en = load_data('/root/userspace/public/chap09/data/train.en')\n",
    "t_train, tokenizer_ja = load_data('/root/userspace/public/chap09/data/train.ja')\n",
    "\n",
    "detokenizer_en = dict(map(reversed, tokenizer_en.word_index.items()))\n",
    "detokenizer_ja = dict(map(reversed, tokenizer_ja.word_index.items()))\n",
    "\n",
    "en_vocab_size = len(tokenizer_en.word_index) + 1\n",
    "ja_vocab_size = len(tokenizer_ja.word_index) + 1\n",
    "\n",
    "x_train, _, t_train, _ = train_test_split(x_train, t_train, test_size=0.5, random_state=42) # 演習用に縮小\n",
    "x_train, x_test, t_train, t_test = train_test_split(x_train, t_train, test_size=0.02, random_state=42)\n",
    "x_train, x_valid, t_train, t_valid = train_test_split(x_train, t_train, test_size=0.02, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、後ほど学習結果の確認で利用するため、複数の系列の中から`num`番目の系列をBOSとEOSを除いた上で取得する関数を定義しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_id_ja, eos_id_ja = tokenizer_ja.texts_to_sequences(['<s> </s>'])[0]\n",
    "\n",
    "def get_raw_contents(dataset, num, bos_id, eos_id):\n",
    "    result = []\n",
    "    for index in dataset[num]:\n",
    "        if index == eos_id:\n",
    "            break\n",
    "            \n",
    "        result.append(index)\n",
    "        \n",
    "        if index == bos_id:\n",
    "            result = []\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_log(x):\n",
    "    return tf.log(tf.clip_by_value(x, 1e-10, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 各層クラスの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Embedding層\n",
    "\n",
    "実際にEmbedding層の処理を担うembedding_lookupでは、入力をone_hotベクトルに変換し、Embedding層の行列に掛け、対応する列ベクトルを選択します。\n",
    "![embedding](../figures/embedding.png)\n",
    "\n",
    "$$m:\\text{emb_dim}, \\ n : \\text{vocab_size}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self, vocab_size, emb_dim, scale=0.08):\n",
    "        self.V = tf.Variable(tf.random_normal([vocab_size, emb_dim], stddev=scale), name='V')\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return tf.nn.embedding_lookup(self.V, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Long short-term memory (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder-Decoderモデルでは系列対系列の関係を扱うため、新たに状態の出力、系列での出力に対応させる必要があります。\n",
    "\n",
    "また、生成を行う際には1ステップずつ逐次的にLSTMを実行したいので、状態を保持する機能も持たせましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, hid_dim, seq_len, initial_state, return_state = False, return_sequences = False, hold_state = False, name = None):\n",
    "        self.cell = tf.nn.rnn_cell.BasicLSTMCell(hid_dim)\n",
    "        self.initial_state = initial_state\n",
    "        self.seq_len = seq_len\n",
    "        self.return_state = return_state\n",
    "        self.return_sequences = return_sequences\n",
    "        self.hold_state = hold_state\n",
    "        self.name = name\n",
    "\n",
    "    def __call__(self, x):\n",
    "        with tf.variable_scope(self.name):\n",
    "            outputs, state = tf.nn.dynamic_rnn(self.cell, x, self.seq_len, self.initial_state)\n",
    "        \n",
    "        if self.hold_state:\n",
    "            self.initial_state = state\n",
    "        \n",
    "        if not self.return_sequences:\n",
    "            outputs = state.h\n",
    "            \n",
    "        if not self.return_state:\n",
    "            return outputs\n",
    "        \n",
    "        return outputs, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 計算グラフ構築 & パラメータの更新設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は以下のようなモデルを実装してみましょう。（ここでは、図中の`hidden layer 2`は省略します。）\n",
    "\n",
    "<img src=\"../figures/seq2seq.png\" width=\"50%\">\n",
    "\n",
    "引用：https://github.com/tensorflow/nmt\n",
    "\n",
    "モデルの構造としては、\n",
    "\n",
    "- 翻訳したい文をRNNで状態ベクトルによる表現に変換する（**Encoder**）\n",
    "- 上述の状態ベクトルを考慮しつつ、**訳文の1単語先を予測**する（**Decoder**）\n",
    "\n",
    "という大きく2つの部分からなっています。\n",
    "\n",
    "学習タスクとしては、訳文の時点$t$の単語から時点$t+1$の単語の予測タスクとなっていますが、翻訳前の文章も考慮するわけです。\n",
    "\n",
    "なお、誤差関数は多クラス交差エントロピーで、具体的には次のようになります。（ミニバッチサイズ：$N$、系列長：$T$、辞書サイズ：$K$）\n",
    "\n",
    "$$\n",
    "    \\mathrm{E}\\left(\\{\\boldsymbol{S}^{(n)}\\}_{n=1,\\ldots,N},\\{\\boldsymbol{Y}^{(n)}\\}_{n=1,\\ldots,N}\\right) = -\\frac{1}{N}\\sum^N_{n=1}\\sum^T_{t=1}\\sum^K_{k=1} s^{(n)}_{t, k} \\log y^{(n)}_{t, k}\n",
    "$$\n",
    "$$\\left(\\boldsymbol{S}^{(n)} = [\\boldsymbol{s}^{(n)}_1\\ \\ \\boldsymbol{s}^{(n)}_2\\ \\ \\cdots \\ \\ \\boldsymbol{s}^{(n)}_T]\\in\\{0,1\\}^{K \\times T},\\ \\ \\boldsymbol{Y}^{(n)} = [\\boldsymbol{y}^{(n)}_1\\ \\ \\boldsymbol{y}^{(n)}_2\\ \\ \\cdots \\ \\ \\boldsymbol{y}^{(n)}_T]\\in\\mathbb{R}^{K \\times T}\\ \\ \\ n=1,2,\\ldots,N\\right)$$\n",
    "\n",
    "$\\boldsymbol{s}^{(n)}_t$は$n$番目の系列の時点$t$での単語のone_hot表現です。\n",
    "\n",
    "また、各$\\boldsymbol{y}^{(n)}_t$はモデルからの出力なので、モデルのパラメータ$\\boldsymbol{\\theta}$に依存しており, 最適化はこの$\\boldsymbol{\\theta}$について行われます。\n",
    "\n",
    "#### paddingへの対処\n",
    "\n",
    "Encoderへの入力（図中`source input words`）、Decoderへの入力（図中`target input words`）の双方で、短い系列にはpaddingを施して入力します。\n",
    "\n",
    "そこで、EncoderについてはLSTM内でマスク処理を行います。\n",
    "\n",
    "またDecoderでは、padding部分についてはコストが0になるようにします。\n",
    "\n",
    "これは単語がある部分を1、paddingの部分を0とするバイナリのマスクをかけるか、paddingの部分の教師ラベルdの要素をすべて0になるようにします。\n",
    "\n",
    "以下では後者の方法で実装していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # グラフ初期化\n",
    "\n",
    "emb_dim = 256\n",
    "hid_dim = 256\n",
    "\n",
    "x = tf.placeholder(tf.int32, [None, None], name='x')\n",
    "seq_len = tf.reduce_sum(tf.cast(tf.not_equal(x, pad_index), tf.int32), axis=1)\n",
    "t = tf.placeholder(tf.int32, [None, None], name='t')\n",
    "seq_len_t_in = tf.reduce_sum(tf.cast(tf.not_equal(t, pad_index), tf.int32), axis=1) - 1\n",
    "\n",
    "t_out = tf.one_hot(t[:, 1:], depth=ja_vocab_size, dtype=tf.float32)\n",
    "t_out = t_out * tf.expand_dims(tf.cast(tf.not_equal(t[:, 1:], pad_index), tf.float32), axis=-1)\n",
    "\n",
    "initial_state = tf.nn.rnn_cell.LSTMStateTuple(tf.zeros([tf.shape(x)[0], hid_dim]), tf.zeros([tf.shape(x)[0], hid_dim]))\n",
    "\n",
    "# Encoder\n",
    "h_e = Embedding(en_vocab_size, emb_dim)(x)\n",
    "_, encoded_state = LSTM(hid_dim, seq_len, initial_state, return_state=True, name='encoder_lstm')(h_e)\n",
    "\n",
    "# Decoder\n",
    "decoder = [\n",
    "    Embedding(ja_vocab_size, emb_dim),\n",
    "    LSTM(hid_dim, seq_len_t_in, encoded_state, return_sequences=True, name='decoder_lstm'),\n",
    "    tf.layers.Dense(ja_vocab_size, tf.nn.softmax)\n",
    "] # 生成時に再利用するためにモデルの各レイヤーを配列で確保\n",
    "\n",
    "# Decoderに変数を通す\n",
    "h_d = decoder[0](t)\n",
    "h_d = decoder[1](h_d)\n",
    "y = decoder[2](h_d)\n",
    "\n",
    "cost = -tf.reduce_mean(tf.reduce_sum(t_out * tf_log(y[:, :-1]), axis=[1, 2]))\n",
    "\n",
    "train = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_lens = [len(com) for com in x_train]\n",
    "sorted_train_indexes = sorted(range(len(x_train_lens)), key=lambda x: -x_train_lens[x])\n",
    "\n",
    "x_train = [x_train[ind] for ind in sorted_train_indexes]\n",
    "t_train = [t_train[ind] for ind in sorted_train_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 128\n",
    "n_batches = len(x_train) // batch_size\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(n_epochs):\n",
    "    # train\n",
    "    train_costs = []\n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        x_train_batch = np.array(pad_sequences(x_train[start:end], padding='post', value=pad_index))\n",
    "        t_train_batch = np.array(pad_sequences(t_train[start:end], padding='post', value=pad_index))\n",
    "\n",
    "        _, train_cost = sess.run([train, cost], feed_dict={x: x_train_batch, t: t_train_batch})\n",
    "        train_costs.append(train_cost)\n",
    "\n",
    "    # valid\n",
    "    x_valid_pad = np.array(pad_sequences(x_valid, padding='post', value=pad_index))\n",
    "    t_valid_pad = np.array(pad_sequences(t_valid, padding='post', value=pad_index))\n",
    "\n",
    "    valid_cost = sess.run(cost, feed_dict={x: x_valid_pad, t: t_valid_pad})\n",
    "    print('EPOCH: %i, Training Cost: %.3f, Validation Cost: %.3f' % (epoch+1, np.mean(train_costs), valid_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "翻訳文の生成には、先程学習したDecoderモデルに対して、1単語ずつ文末まで繰り返し後続単語の予測を行う必要があります。\n",
    "\n",
    "この繰り返しに`while`ループを使うので、まず`tf`におけるwhileループの実装である`tf.while_loop`について見ていきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  5.1. `tf.while_loop`関数  \\[[link](https://www.tensorflow.org/api_docs/python/tf/while_loop)\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主な引数は以下のとおりです。\n",
    "\n",
    "- 第1引数 `cond`: `True` or `False` を返す関数 (正確にはcallable)\n",
    "- 第2引数 `body`: 各iterationで実行する関数 (正確にはcallable)\n",
    "- 第3引数 `loop_vars`: `cond`及び`body`に最初に渡される変数\n",
    "\n",
    "`cond`で指定された関数の戻り値が`True`である限り`body`で指定された関数を実行し続けます。\n",
    "\n",
    "そして、`loop_vars`で指定された全ての変数に対して、最後のiteration後の値を返します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例えば、入力が5未満であるかぎり1ずつ足す処理を実行したい場合、コードは次のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g0 = tf.Graph() # Encoder-Decoderモデルのグラフと区別するために新しいグラフオブジェクトを作成\n",
    "\n",
    "def cond(z):\n",
    "    return z < 5\n",
    "\n",
    "def body(z):\n",
    "    return z + 1\n",
    "\n",
    "with g0.as_default():\n",
    "    z = tf.constant(0)\n",
    "\n",
    "    res = tf.while_loop(cond, body, [z])\n",
    "\n",
    "with tf.Session(graph=g0) as sess_g0:\n",
    "    print(sess_g0.run(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、`tf.while_loop`の各iteration後の変数の`shape`はデフォルトでは同じであることが指定されています。\n",
    "\n",
    "したがって、各iteration後の`shape`が変化する場合は、この条件を緩和する必要があります。\n",
    "\n",
    "例えば、上の1ずつ足すプログラムですべてのiteration後の値を保持して返したい場合、各iterationの戻り値は\n",
    "\n",
    "```\n",
    "[1], [1, 2], [1, 2, 3], [1, 2, 3, 4], ...\n",
    "```\n",
    "となっていくので、それぞれの`shape`は\n",
    "```\n",
    "(1,), (2,), (3,), (4,), ...\n",
    "```\n",
    "と変化していきます。\n",
    "\n",
    "つまり、この例ではベクトルの次元数が変化していくので、`shape_invariants`で`shape`を`[None]` (実際は`tf.TensorShape([None])`と指定します。\n",
    "\n",
    "具体的なコードは次のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = tf.Graph() # Encoder-Decoderモデルのグラフと区別するために新しいグラフオブジェクトを作成\n",
    "\n",
    "def cond(z):\n",
    "    return z[-1] < 5\n",
    "\n",
    "def body(z):\n",
    "    return tf.concat([z, z[-1:]+1], axis=0)\n",
    "\n",
    "with g1.as_default():\n",
    "    z = tf.zeros(1)\n",
    "\n",
    "    res = tf.while_loop(\n",
    "        cond,\n",
    "        body,\n",
    "        [z],\n",
    "        shape_invariants=[tf.TensorShape([None])]\n",
    "    )\n",
    "\n",
    "with tf.Session(graph=g1) as sess_g1:\n",
    "    print(sess_g1.run(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2x1行列に対して同じような操作をしたい場合は次のようになります。この場合各iteration後の行列の`shape`は\n",
    "```\n",
    "(2, 1), (2, 2), (2, 3), (2, 4), ...\n",
    "```\n",
    "と列数のみ変化していくので、`shape_invariants`には`tf.TensorShape([2, None])`と指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g2 = tf.Graph() # Encoder-Decoderモデルのグラフと区別するために新しいグラフオブジェクトを作成\n",
    "\n",
    "\n",
    "def cond(z):\n",
    "    return tf.reduce_sum(z[:, -1]) < 5*2\n",
    "\n",
    "def body(z):\n",
    "    return tf.concat([z, z[:, -1:]+1], axis=1)\n",
    "\n",
    "with g2.as_default():\n",
    "    z = tf.zeros([2, 1])\n",
    "\n",
    "    res = tf.while_loop(\n",
    "        cond,\n",
    "        body,\n",
    "        [z],\n",
    "        shape_invariants=[tf.TensorShape([2, None])]\n",
    "    )\n",
    "\n",
    "with tf.Session(graph=g2) as sess_g2:\n",
    "    print(sess_g2.run(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "詳細は公式のドキュメントを参照してください。\n",
    "\n",
    "- tf.while_loop: https://www.tensorflow.org/api_docs/python/tf/while_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. グラフの構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "未知の入力に対してEncoder-Decoderモデルを適用するとき、正解ラベル$d$はわかりません。\n",
    "\n",
    "そこで、代わりに前のステップで予測した単語を各ステップでの入力とします。そして、系列の終わりを表す単語 (`</s>`) が出力されるまで繰り返します。\n",
    "\n",
    "具体的には、$\\boldsymbol{h}_{t-1}, \\boldsymbol{c}_{t-1}, \\boldsymbol{y}_{t-1}$を入力として$\\boldsymbol{y}_t$を受け取る操作を、バッチ内の全てのサンプルにおける$\\boldsymbol{y}_t$が`</s>`となるまで続けます。\n",
    "\n",
    "なお、各ステップで順伝播後の`decorder_lstm`の`state`を取得したいので、`decorder_lstm`の`hold_state`をオンにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_eos = tf.placeholder(tf.int32, [2], name='bos_eos')\n",
    "max_len = tf.placeholder(tf.int32, name='max_len') # iterationの繰り返し回数の限度\n",
    "\n",
    "def cond(t, continue_flag, init_state, seq_last, seq):\n",
    "    unfinished = tf.not_equal(tf.reduce_sum(tf.cast(continue_flag, tf.int32)), 0)\n",
    "    return tf.logical_and(t < max_len, unfinished)\n",
    "\n",
    "def body(t, prev_continue_flag, init_state, seq_last, seq):\n",
    "    decoder[1].initial_state = init_state\n",
    "    \n",
    "    # Decoderの再構築\n",
    "    h = decoder[0](tf.expand_dims(seq_last, axis=-1))\n",
    "    h = decoder[1](h)\n",
    "    y = decoder[2](h)\n",
    "    \n",
    "    seq_t = tf.reshape(tf.cast(tf.argmax(y, axis=2), tf.int32), shape=[-1])\n",
    "    next_state = decoder[1].initial_state\n",
    "    \n",
    "    continue_flag = tf.logical_and(prev_continue_flag, tf.not_equal(seq_t, bos_eos[1])) # flagの更新\n",
    "\n",
    "    return [t+1, continue_flag, next_state, seq_t, seq.write(t, seq_t)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decoder[1].hold_state = True\n",
    "decoder[1].seq_len = None\n",
    "\n",
    "seq_0 = tf.ones([tf.shape(x)[0]], tf.int32)*bos_eos[0]\n",
    "\n",
    "t_0 = tf.constant(1)\n",
    "f_0 = tf.cast(tf.ones_like(seq_0), dtype=tf.bool) # バッチ内の各系列で</s>が出たかどうかの未了flag(0:出た, 1:出てない)\n",
    "seq_array = tf.TensorArray(dtype=tf.int32, size=1, dynamic_size=True).write(0, seq_0)\n",
    "\n",
    "*_, seq = tf.while_loop(cond, body, loop_vars=[t_0, f_0, encoded_state, seq_0, seq_array])\n",
    "\n",
    "res = tf.transpose(seq.stack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3. 生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = sess.run(res, feed_dict={\n",
    "    x: pad_sequences(x_test, padding='post', value=pad_index),\n",
    "    bos_eos: np.array([bos_id_ja, eos_id_ja]),\n",
    "    max_len: 100\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4. 生成例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num = 0\n",
    "pred = get_raw_contents(y_pred, num, bos_id_ja, eos_id_ja)\n",
    "\n",
    "print('元の文:', ' '.join([detokenizer_en[com] for com in x_test[num][1:-1]]))\n",
    "print('生成文:', ' '.join([detokenizer_ja[com] for com in pred]))\n",
    "print('正解文:', ' '.join([detokenizer_ja[com] for com in t_test[num][1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題2. Attentionを用いた機械翻訳モデルの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Attention層の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は Luong et al., 2015のGlobal attentionモデルを実装します。\n",
    "\n",
    "- \"Effective Approaches to Attention-based Neural Machine Translation\", Minh-Thang Luong et al., EMNLP 2015 https://arxiv.org/abs/1508.04025\n",
    "\n",
    "課題1で実装したモデルは左図、ここで実装するモデルは右図になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../figures/attention-1.png\" width=\"1000mm\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoderの各ステップにおける計算の手順\n",
    "\n",
    "Encoderの各ステップの隠れ層を\n",
    "\n",
    "$$\n",
    "    \\boldsymbol{\\bar{h}} = \\{\\boldsymbol{\\bar{h}}_1, \\boldsymbol{\\bar{h}}_2, \\ldots, \\boldsymbol{\\bar{h}}_s, \\ldots, \\boldsymbol{\\bar{h}}_S\\}\n",
    "$$\n",
    "\n",
    "Decoderの各ステップの隠れ層を\n",
    "\n",
    "$$\n",
    "    \\boldsymbol{h} = \\{\\boldsymbol{h}_1, \\boldsymbol{h}_2, \\ldots, \\boldsymbol{h}_t, \\ldots, \\boldsymbol{h}_T\\}\n",
    "$$\n",
    "\n",
    "とします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention Layerの計算手順は以下のようになります。\n",
    "\n",
    "1. Decoderの各時点の出力に対して、入力系列のどのステップに注目するかを表すscore関数の値を計算します。\n",
    "$$\n",
    "   \\mathrm{score}\\left(\\boldsymbol{\\bar{h}}_s,\\ \\boldsymbol{h}_t\\right) = \\boldsymbol{h}_t^{\\mathrm{T}} \\boldsymbol{W}_a \\boldsymbol{\\bar{h}}_s\n",
    "$$\n",
    "なお、score関数には任意性があり、今回用いる関数以外にも例えば以下の様なものが提案されています。\n",
    "$$\n",
    "\\mathrm{score}\\left(\\boldsymbol{\\bar{h}}_s,\\ \\boldsymbol{h}_t\\right) =\n",
    "\\begin{cases}\n",
    "    {\\boldsymbol{h}_t}^{\\mathrm{T}} \\boldsymbol{\\bar{h}}_s \\\\\n",
    "    \\boldsymbol{v}^{\\mathrm{T}} \\tanh\\left(\\boldsymbol{W}_{ad} \\boldsymbol{h}_t + \\boldsymbol{W}_{ae} \\boldsymbol{\\bar{h}}_s\\right)\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "2. 次にscoreをsoftmax関数により**重み**$\\ \\boldsymbol{a}_t(s)$に変換します。\n",
    "$$\n",
    "    \\boldsymbol{a}_t(s) = \\frac{\\exp\\left[\\mathrm{score}\\left(\\boldsymbol{\\bar{h}}_s,\\ \\boldsymbol{h}_t\\right)\\right]}{\\sum^S_{s'=1}\\exp\\left[\\mathrm{score}\\left(\\boldsymbol{\\bar{h}}_s,\\ \\boldsymbol{h}_t\\right)\\right]}\n",
    "$$\n",
    "3. 2.で計算した重みを元に、Encoderの出力の加重平均ベクトル (**文脈ベクトル**) $\\boldsymbol{c}_t$ を計算します。\n",
    "$$\n",
    "    \\boldsymbol{c}_t = \\sum^S_{s=1} \\boldsymbol{a}_t(s) \\boldsymbol{\\bar{h}}_s\n",
    "$$\n",
    "4. 3.で計算した文脈ベクトル$\\boldsymbol{c}_t$と元の出力$\\boldsymbol{h}_t$から、新しい出力ベクトル$\\boldsymbol{\\tilde{h}}_t$を計算します。\n",
    "$$\n",
    "    \\boldsymbol{\\tilde{h}}_t = \\tanh\\left(\\boldsymbol{W}_c \\left[\\begin{array}{c} \\boldsymbol{c}_t \\\\ \\boldsymbol{h}_t \\end{array}\\right] + \\boldsymbol{b}\\right)\n",
    "$$\n",
    "\n",
    "論文では$\\boldsymbol{\\tilde{h}}_t$が次のタイムステップのLSTMにfeedされる方法も示されており、他の論文でもそのようにしているものも多いです。\n",
    "\n",
    "その場合、Attention層とLSTM層は分けずに、同じクラスで書くことになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attentionのマスクについて\n",
    "\n",
    "先程と同様、ミニバッチ化の際には短い系列に対してpaddingを行いますが、Encoderのpadding部分にはAttentionの適用も回避したいわけです。\n",
    "\n",
    "そこで、padding部分は$\\exp\\left[\\mathrm{score}\\left(\\boldsymbol{\\bar{h}}_s,\\ \\boldsymbol{h}_t\\right)\\right]$ が0になるように (score関数の値がとても小さな値になるように) マスクをかけます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention:\n",
    "    def __init__(self, hid_dim, out_dim, enc_out, seq_len):\n",
    "        e_hid_dim, d_hid_dim = hid_dim, hid_dim\n",
    "        \n",
    "        self.enc_out = enc_out\n",
    "        self.seq_len = seq_len\n",
    "        glorot_a = tf.cast(tf.sqrt(6/(e_hid_dim + d_hid_dim)), tf.float32)\n",
    "        self.W_a  = tf.Variable(tf.random_uniform([e_hid_dim, d_hid_dim], minval=-glorot_a, maxval=glorot_a), name='W_a')\n",
    "        \n",
    "        glorot_c = tf.cast(tf.sqrt(6/(e_hid_dim + d_hid_dim + out_dim)), tf.float32)\n",
    "        self.W_c = tf.Variable(tf.random_uniform([e_hid_dim+d_hid_dim, out_dim], minval=-glorot_c, maxval=glorot_c), name='W_c')\n",
    "        self.b    = tf.Variable(np.zeros([out_dim]).astype('float32'), name='b')\n",
    "        \n",
    "    def __call__(self, dec_out):\n",
    "        # self.enc_out: [batch_size, enc_length, e_hid_dim]\n",
    "        # self.W_a  : [e_hid_dim, d_hid_dim]\n",
    "        # -> enc_out: [batch_size, enc_length, d_hid_dim]\n",
    "        W_a_broadcasted = tf.tile(tf.expand_dims(self.W_a, axis=0), [tf.shape(self.enc_out)[0],1,1])\n",
    "        enc_out = tf.matmul(self.enc_out, W_a_broadcasted)\n",
    "        \n",
    "        # dec_out: [batch_size, dec_length, d_hid_dim]\n",
    "        # enc_out: [batch_size, enc_length, d_hid_dim]\n",
    "        # -> score: [batch_size, dec_length, enc_length]\n",
    "        score = tf.matmul(dec_out, tf.transpose(enc_out, perm=[0,2,1])) # Attention score\n",
    "        \n",
    "        # encoderのステップにそって正規化する\n",
    "        score = score - tf.reduce_max(score, axis=-1, keep_dims=True) # for numerically stable softmax\n",
    "        mask = tf.cast(tf.sequence_mask(self.seq_len, tf.shape(score)[-1]), tf.float32) # encoder mask\n",
    "        exp_score = tf.exp(score) * tf.expand_dims(mask, axis=1)\n",
    "        self.a = exp_score / tf.reduce_sum(exp_score, axis=-1, keep_dims=True) # softmax\n",
    "\n",
    "        # self.a  : [batch_size, dec_length, enc_length]\n",
    "        # self.enc_out: [batch_size, enc_length, e_hid_dim]\n",
    "        # -> c: [batch_size, dec_length, e_hid_dim]\n",
    "        c = tf.matmul(self.a, self.enc_out) # Context vector\n",
    "\n",
    "        W_c_broadcasted = tf.tile(tf.expand_dims(self.W_c, axis=0), [tf.shape(c)[0],1,1])\n",
    "\n",
    "        return tf.nn.tanh(tf.matmul(tf.concat([c, dec_out], -1), W_c_broadcasted) + self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 計算グラフ構築 & パラメータの更新設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # グラフ初期化\n",
    "\n",
    "emb_dim = 512\n",
    "hid_dim = 256\n",
    "att_dim = 128\n",
    "\n",
    "x = tf.placeholder(tf.int32, [None, None], name='x')\n",
    "seq_len = tf.reduce_sum(tf.cast(tf.not_equal(x, pad_index), tf.int32), axis=1)\n",
    "t = tf.placeholder(tf.int32, [None, None], name='t')\n",
    "seq_len_t_in = tf.reduce_sum(tf.cast(tf.not_equal(t, pad_index), tf.int32), axis=1) - 1\n",
    "\n",
    "t_out = tf.one_hot(t[:, 1:], depth=ja_vocab_size, dtype=tf.float32)\n",
    "t_out = t_out * tf.expand_dims(tf.cast(tf.not_equal(t[:, 1:], pad_index), tf.float32), axis=-1)\n",
    "\n",
    "initial_state = tf.nn.rnn_cell.LSTMStateTuple(tf.zeros([tf.shape(x)[0], hid_dim]), tf.zeros([tf.shape(x)[0], hid_dim]))\n",
    "\n",
    "# Encoder\n",
    "h_e = Embedding(en_vocab_size, emb_dim)(x)\n",
    "encoded_outputs, encoded_state = LSTM(hid_dim, seq_len, initial_state, return_sequences=True, return_state=True, name='encoder_lstm_a')(h_e)\n",
    "\n",
    "# Decoder\n",
    "decoder = [\n",
    "    Embedding(ja_vocab_size, emb_dim),\n",
    "    LSTM(hid_dim, seq_len_t_in, encoded_state, return_sequences=True, name='decoder_lstm_a'),\n",
    "    Attention(hid_dim, att_dim, encoded_outputs, seq_len),\n",
    "    tf.layers.Dense(ja_vocab_size, tf.nn.softmax)\n",
    "] # 生成時に再利用するためにまとめて確保\n",
    "\n",
    "h_d = decoder[0](t)\n",
    "h_d = decoder[1](h_d)\n",
    "h_d = decoder[2](h_d)\n",
    "y = decoder[3](h_d)\n",
    "\n",
    "cost = -tf.reduce_mean(tf.reduce_sum(t_out * tf_log(y[:, :-1]), axis=[1, 2]))\n",
    "\n",
    "train = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "n_epochs = 15\n",
    "batch_size = 128\n",
    "n_batches_train = len(x_train)//batch_size\n",
    "n_batches_valid = len(x_valid)//batch_size\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Train\n",
    "    train_costs = []\n",
    "    for i in range(n_batches_train):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        \n",
    "        x_train_batch = np.array(pad_sequences(x_train[start:end], padding='post', value=pad_index))\n",
    "        t_train_batch = np.array(pad_sequences(t_train[start:end], padding='post', value=pad_index))\n",
    "        \n",
    "        _, train_cost = sess.run([train, cost], feed_dict={x: x_train_batch, t: t_train_batch})\n",
    "        train_costs.append(train_cost)\n",
    "\n",
    "    # Valid\n",
    "    valid_costs = []\n",
    "    for i in range(n_batches_valid):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        \n",
    "        x_valid_pad = np.array(pad_sequences(x_valid[start:end], padding='post', value=pad_index))\n",
    "        t_valid_pad = np.array(pad_sequences(t_valid[start:end], padding='post', value=pad_index))\n",
    "        \n",
    "        valid_cost = sess.run(cost, feed_dict={x: x_valid_pad, t: t_valid_pad})\n",
    "        valid_costs.append(valid_cost)\n",
    "\n",
    "    print('EPOCH: %i, Training Cost: %.3f, Validation Cost: %.3f' % (epoch+1, np.mean(train_costs), np.mean(valid_costs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 翻訳文の生成とattention weightの可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. グラフの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_eos = tf.placeholder(tf.int32, [2], name='bos_eos')\n",
    "max_len = tf.placeholder(tf.int32, name='max_len') # iterationの繰り返し回数の限度\n",
    "\n",
    "def cond(t, continue_flag, init_state, seq_last, seq, att):\n",
    "    unfinished = tf.not_equal(tf.reduce_sum(tf.cast(continue_flag, tf.int32)), 0)\n",
    "    return tf.logical_and(t < max_len, unfinished)\n",
    "\n",
    "def body(t, prev_continue_flag, init_state, seq_last, seq, att):\n",
    "    decoder[1].initial_state = init_state\n",
    "    \n",
    "    # Decoderグラフを再構築\n",
    "    h = decoder[0](tf.expand_dims(seq_last, -1))\n",
    "    h = decoder[1](h)\n",
    "    h = decoder[2](h)\n",
    "    y = decoder[3](h)\n",
    "    \n",
    "    seq_t = tf.reshape(tf.cast(tf.argmax(y, axis=2), tf.int32), shape=[-1])\n",
    "    next_state = decoder[1].initial_state\n",
    "    \n",
    "    continue_flag = tf.logical_and(prev_continue_flag, tf.not_equal(seq_t, bos_eos[1])) # flagの更新\n",
    "\n",
    "    return [t+1, continue_flag, next_state, seq_t, seq.write(t, seq_t), att.write(t-1, tf.squeeze(decoder[2].a))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decoder[1].hold_state = True\n",
    "decoder[1].seq_len = None\n",
    "\n",
    "seq_0 = tf.ones([tf.shape(x)[0]], tf.int32)*bos_eos[0]\n",
    "\n",
    "t_0 = tf.constant(1)\n",
    "f_0 = tf.cast(tf.ones_like(seq_0), dtype=tf.bool) # バッチ内の各系列で</s>が出たかどうかの未了flag(0:出た, 1:出てない)\n",
    "seq_array = tf.TensorArray(dtype=tf.int32, size=1, dynamic_size=True).write(0, seq_0)\n",
    "att_array = tf.TensorArray(dtype=tf.float32, size=1, dynamic_size=True)\n",
    "\n",
    "*_, seq, att = tf.while_loop(cond, body, loop_vars=[t_0, f_0, encoded_state, seq_0, seq_array, att_array])\n",
    "\n",
    "res = (tf.transpose(seq.stack()), tf.transpose(att.stack(), perm=[1, 0, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. 生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, att_weights = sess.run(res, feed_dict={\n",
    "    x: pad_sequences(x_test, padding='post', value=pad_index),\n",
    "    bos_eos: np.array([bos_id_ja, eos_id_ja]),\n",
    "    max_len: 100\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. 生成例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "\n",
    "pred = get_raw_contents(y_pred, num, bos_id_ja, eos_id_ja)\n",
    "\n",
    "print('元の文:', ' '.join([detokenizer_en[com] for com in x_test[num][1:-1]]))\n",
    "print('生成文:', ' '.join([detokenizer_ja[com] for com in pred]))\n",
    "print('正解文:', ' '.join([detokenizer_ja[com] for com in t_test[num][1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4. アテンションの可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`matplotlib`でアテンションを可視化してみましょう。\n",
    "\n",
    "具体的には訳文の生成に当たって、原文のどの単語をどれだけ重視したかをヒートマップで表示します。\n",
    "\n",
    "まず、`matplotlib`はデフォルトでは日本語が文字化けしてしまうので、日本語フォントのインストールを行います。\n",
    "\n",
    "今回はTakaoフォント (https://launchpad.net/takao-fonts) を利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm ~/.cache/matplotlib/fontlist-v300.json\n",
    "wget -q https://s3.amazonaws.com/ilect-public/ail/TakaoPGothic.ttf\n",
    "mv TakaoPGothic.ttf /usr/local/lib/python3.5/dist-packages/matplotlib/mpl-data/fonts/ttf/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アテンションで獲得した重み$a = [\\boldsymbol{a}_1(s)\\ \\ \\boldsymbol{a}_2(s)\\ \\ \\cdots\\ \\ \\boldsymbol{a}_T(s)]$を可視化してみます。\n",
    "\n",
    "縦軸に訳文、横軸に原文を表示し、重みをヒートマップで表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# BOSは生成したものでないので除外されることに注意\n",
    "pred = get_raw_contents(y_pred, num, bos_id_ja, eos_id_ja) + [eos_id_ja]\n",
    "\n",
    "# アテンションの重み\n",
    "attention = att_weights[num][:len(pred), :len(x_test[num])]\n",
    "\n",
    "# 軸ラベル（x：原文、y：訳文）\n",
    "xticks = [detokenizer_en[com] for com in x_test[num]]\n",
    "yticks = [detokenizer_ja[com] for com in pred]\n",
    "\n",
    "# figure & axes の生成\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# ヒートマップの作製\n",
    "ax.pcolor(attention, cmap=plt.cm.Blues)\n",
    "\n",
    "# 重みの値を表示\n",
    "for (cord_y, cord_x), w in np.ndenumerate(attention):\n",
    "    ax.annotate(format(w, '.2f'), xy=(cord_x+0.5, cord_y+0.5), ha='center', va='center',\n",
    "                fontsize=12, color=str(round(w)), fontweight='bold')\n",
    "\n",
    "# 軸の調整（メモリ位置、軸の向き・配置・ラベル）\n",
    "ax.set_xticks(np.arange(attention.shape[1]) + 0.5)\n",
    "ax.set_yticks(np.arange(attention.shape[0]) + 0.5)\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.xaxis.tick_top()\n",
    "\n",
    "ax.set_xticklabels(xticks, fontsize=12, color='r', fontweight='bold')\n",
    "ax.set_yticklabels(yticks, fontsize=12, color='b', fontweight='bold', fontdict={'family': 'TakaoPGothic'})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【補足】機械翻訳の評価について\n",
    "\n",
    "これまで、基本的に学習したモデルの良し悪しについては損失をベースに考えてきました。\n",
    "\n",
    "ですが機械翻訳の場合、損失と翻訳の精度が必ずしも一致しません。\n",
    "\n",
    "というのも、翻訳においては、単純に各単語が一致しているか否か以上に、意味的な繋がりや表現の流暢さが重要となるためです。\n",
    "\n",
    "また、必ずしも語順についても一致している必要はありません。\n",
    "\n",
    "そこで、そうした翻訳タスク特有の性質を反映した評価指標が必要となります。その代表例として、**BLEUスコア**が挙げられます。\n",
    "\n",
    "BLEUスコアは、n-gram（連続n単語、主にn=4）がどれだけ生成文と正解文で共有されているかなどを考慮した指標となっています。\n",
    "\n",
    "詳細な算出方法等に興味がある方はスクリプト ( http://www.nltk.org/_modules/nltk/translate/bleu_score.html ) をのぞいてみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "prediction = ['I', 'am', 'a', 'graduate', 'student', 'at', 'a', 'university']\n",
    "reference = [['I', 'am', 'a', 'graduate', 'student', 'at', 'the', 'university', 'of', 'tokyo']]\n",
    "\n",
    "print(sentence_bleu(reference, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num = 0\n",
    "\n",
    "gen = [detokenizer_ja[com] for com in get_raw_contents(y_pred, num, bos_id_ja, eos_id_ja)]\n",
    "ref = [detokenizer_ja[com] for com in t_valid[num][1:-1]]\n",
    "\n",
    "print(gen)\n",
    "print(ref)\n",
    "\n",
    "print(sentence_bleu(ref, gen, smoothing_function=SmoothingFunction().method1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【補足】Beam searchについて\n",
    "\n",
    "ここまで生成については、常に各時点で最大の確率を持つ単語を選択していました。（貪欲法）\n",
    "\n",
    "ですが、これは局所的（各時点）には最適であっても、大域的（生成した系列全体）に見て最適とは限りません。\n",
    "\n",
    "とはいえ、大域的に最適な系列を生成するには、各時点で全候補（正の確率を持つ全単語）を列挙し、その全候補に対して再び生成を行う必要があります。\n",
    "\n",
    "すなわち、単語集合$\\mathcal{V}$、系列長$T$のとき大雑把に言えば$|\\mathcal{V}|^T$通りの系列を生成する必要があり、とても現実的ではありません。\n",
    "\n",
    "そこでこの全列挙とこれまでの貪欲法の中間を考えることで、現実的な計算時間でより大域的な評価を考慮に入れた生成が可能になります。\n",
    "\n",
    "この手法を**Beam search**と呼びます。内容としては、各時点で上位$K$個だけの候補を残しながら系列を生成するという単純なものです。\n",
    "\n",
    "以下に参考までにBeam searchによる生成部分のコードを記載しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "\n",
    "bos_eos = tf.placeholder(tf.int32, [2], name='bos_eos')\n",
    "max_len = tf.placeholder(tf.int32, name='max_len') # iterationの繰り返し回数の限度\n",
    "\n",
    "def batch_gather(param, index):\n",
    "    if index.shape.ndims == 1:\n",
    "        return tf.gather_nd(param, tf.expand_dims(index, axis=-1))\n",
    "    batch_index = tf.expand_dims(tf.tile(tf.expand_dims(tf.range(tf.shape(index)[0]), axis=-1), [1,tf.shape(index)[1]]), axis=-1)\n",
    "    gather_index = tf.concat([batch_index, tf.expand_dims(index, axis=-1)], axis=-1)\n",
    "    return tf.gather_nd(param, gather_index)\n",
    "    \n",
    "# beam search用ループ関数 (系列長方向へのループ)\n",
    "def cond(t, continue_flag, init_state, seq_last, cum_ll, seq, ll, link):\n",
    "    unfinished = tf.not_equal(tf.reduce_sum(tf.cast(continue_flag, tf.int32)), 0)\n",
    "    return tf.logical_and(t+1 < max_len, unfinished)\n",
    "\n",
    "def body(t, prev_continue_flag, init_state, seq_last, cum_ll, seq, ll, link):\n",
    "    # beam search用ループ関数 (top_k候補方向へのループ)\n",
    "    def inner_cond(k, init_state, seq_last, cand_ll, cand_ids, next_state):\n",
    "        return k < K\n",
    "    \n",
    "    def inner_body(k, init_state, seq_last, cand_ll, cand_ids, next_state):\n",
    "        decoder[1].initial_state = tf.nn.rnn_cell.LSTMStateTuple(init_state[k][0], init_state[k][1])\n",
    "    \n",
    "        # Decoderグラフを再構築\n",
    "        h = decoder[0](tf.expand_dims(seq_last[:,k], axis=-1))\n",
    "        h = decoder[1](h)\n",
    "        h = decoder[2](h)\n",
    "        y = decoder[3](h)\n",
    "        \n",
    "        # 直前の各top_K候補に対してtop_Kだけ現時点の候補を残すようスクリーニング\n",
    "        cand_ll_k, cand_ids_k = tf.nn.top_k(tf.log(tf.reshape(y, shape=[tf.shape(x)[0],-1])), k=K)\n",
    "        \n",
    "        cand_ll_k = tf.expand_dims(cand_ll_k, axis=0)\n",
    "        cand_ids_k = tf.expand_dims(cand_ids_k, axis=0)\n",
    "        state = tf.expand_dims(decoder[1].initial_state, axis=0)\n",
    "        \n",
    "        # 記録\n",
    "        indices = tf.eye(K, dtype=tf.int32)[k]\n",
    "        cand_ll += batch_gather(tf.concat([tf.zeros_like(cand_ll_k), cand_ll_k], axis=0), indices)\n",
    "        cand_ids += batch_gather(tf.concat([tf.zeros_like(cand_ids_k), cand_ids_k], axis=0), indices)\n",
    "        next_state += batch_gather(tf.concat([tf.zeros_like(state), state], axis=0), indices)\n",
    "        \n",
    "        return [k+1, init_state, seq_last, cand_ll, cand_ids, next_state]\n",
    "    \n",
    "    # top_K方向へのループの構築\n",
    "    cand_ll = tf.zeros([K, tf.shape(seq_last)[0], K], tf.float32) # [prev_top_K, batch_size, current_top_K]\n",
    "    cand_ids = tf.zeros([K, tf.shape(seq_last)[0], K], tf.int32)\n",
    "    next_state = tf.zeros_like(init_state)\n",
    "    \n",
    "    *_, cand_ll, cand_ids, next_state = tf.while_loop(inner_cond, inner_body, loop_vars=[tf.constant(0), init_state, seq_last, cand_ll, cand_ids, next_state])\n",
    "\n",
    "    # K-majorからbatch-majorに\n",
    "    cand_ll = tf.transpose(cand_ll, perm=[1, 0, 2])\n",
    "    cand_ids = tf.transpose(cand_ids, perm=[1, 0, 2])\n",
    "    \n",
    "    # </s>以降に対するマスクの適用\n",
    "    mask = tf.expand_dims(tf.cast(prev_continue_flag, tf.int32), axis=-1)\n",
    "    cand_ll = cand_ll * tf.cast(mask, tf.float32)\n",
    "    cand_ids = cand_ids * mask - (1-mask)\n",
    "    \n",
    "    # 累積尤度へ変換\n",
    "    cand_cum_ll = cand_ll + tf.expand_dims(cum_ll, axis=-1)\n",
    "    \n",
    "    # 現時点でのtop_Kの決定\n",
    "    top_k_cum_ll, top_k_place = tf.nn.top_k(tf.reshape(cand_cum_ll, shape=[-1, K*K]), k=K) # [batch_size, K*K]\n",
    "    \n",
    "    # top_Kの情報出力 (id、対数尤度、直前のid：後者2つは後ほど可視化に利用)\n",
    "    seq_t = batch_gather(tf.reshape(cand_ids, shape=[-1, K*K]), top_k_place)\n",
    "    seq_t_ll = batch_gather(tf.reshape(cand_ll, shape=[-1, K*K]), top_k_place)\n",
    "    seq_t_prev = tf.floordiv(top_k_place, K) # [batch_size, top_K]:各要素はprev_state\n",
    "    \n",
    "    # 次時点の初期状態の選定\n",
    "    next_state = tf.transpose(next_state, perm=[2, 0, 1, 3]) # [prev_state, lstm_state_type, batch_size, hid_dim] -> [batch_size, prev_state, lstm_state_type, hid_dim]\n",
    "    next_state = batch_gather(next_state, seq_t_prev)\n",
    "    next_state = tf.transpose(next_state, perm=[1, 2, 0, 3])\n",
    "    \n",
    "    # flagの更新\n",
    "    continue_flag = tf.logical_and(prev_continue_flag, tf.not_equal(seq_t, bos_eos[1]))\n",
    "\n",
    "    return [t+1, continue_flag, next_state, seq_t, top_k_cum_ll,\n",
    "            seq.write(t, seq_t), ll.write(t, seq_t_ll), link.write(t, seq_t_prev)]\n",
    "\n",
    "decoder[1].hold_state = True\n",
    "decoder[1].seq_len = None\n",
    "\n",
    "# 初期値生成\n",
    "batch_size = tf.shape(x)[0]\n",
    "seq_0 = tf.ones([batch_size], tf.int32)*bos_eos[0]\n",
    "decoder[1].initial_state = encoded_state\n",
    "\n",
    "h = decoder[0](tf.expand_dims(seq_0, axis=-1))\n",
    "h = decoder[1](h)\n",
    "h = decoder[2](h)\n",
    "y = decoder[3](h)\n",
    "\n",
    "cum_ll_0, seq_0 = tf.nn.top_k(tf.log(tf.reshape(y, shape=[batch_size,-1])), k=K)\n",
    "init_state = tf.tile(tf.expand_dims(decoder[1].initial_state, axis=0), [K,1,1,1])\n",
    "\n",
    "t_0 = tf.constant(1)\n",
    "f_0 = tf.cast(tf.ones_like(seq_0), dtype=tf.bool) # バッチ内の各系列で</s>が出たかどうかの未了flag(0:出た, 1:出てない)\n",
    "seq_array = tf.TensorArray(dtype=tf.int32, size=1, dynamic_size=True).write(0, seq_0)\n",
    "ll_array = tf.TensorArray(dtype=tf.float32, size=1, dynamic_size=True).write(0, cum_ll_0)\n",
    "link_array = tf.TensorArray(dtype=tf.int32, size=1, dynamic_size=True).write(0, tf.zeros([batch_size, K], tf.int32))\n",
    "\n",
    "# beam searchループ構築\n",
    "*_, seq, ll, link = tf.while_loop(cond, body, loop_vars=[t_0, f_0, init_state, seq_0, cum_ll_0, seq_array, ll_array, link_array])\n",
    "\n",
    "# 結果出力（TensorArrayのTensorへの変換）\n",
    "res = (tf.transpose(seq.stack(), perm=[1, 0, 2]), tf.transpose(ll.stack(), perm=[1, 0, 2]), tf.transpose(link.stack(), perm=[1, 0, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, ll, link = sess.run(res, feed_dict={\n",
    "    x: pad_sequences(x_test, padding='post', value=pad_index),\n",
    "    bos_eos: np.array([bos_id_ja, eos_id_ja]),\n",
    "    max_len: 100\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成結果は以下のようにしてグラフで可視化できます。\n",
    "\n",
    "赤いノードの系列が最適な生成と予想されたものになります。\n",
    "\n",
    "（以下のコードでnx.nx_agraph.graphviz_layoutによって表示する場合には別途PyGraphvizのインストールが必要です）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rest_rows(G, root, result = None):\n",
    "    if result is None:\n",
    "        result = {}\n",
    "\n",
    "    result[root] = sum([rest_rows(G, node, result)[node] for node in G.successors(root)])\n",
    "    if result[root] == 0:\n",
    "        result[root] = 1\n",
    "\n",
    "    return result\n",
    "\n",
    "def hierarchy_pos(G, root, coord = (0, 0.5), y_offset = 0, height=1., dx = 0.2, pos = None):\n",
    "    rows = rest_rows(G, root)\n",
    "    \n",
    "    if pos is None:\n",
    "        pos = {root:coord}\n",
    "    else:\n",
    "        pos[root] = coord\n",
    "        \n",
    "    for node in G.successors(root):\n",
    "        new_height = rows[node]*height/rows[root]\n",
    "        new_coord = (coord[0] + dx, y_offset + new_height/2)\n",
    "        pos = hierarchy_pos(G, node, new_coord, y_offset, new_height, dx, pos=pos)\n",
    "        y_offset += new_height\n",
    "    \n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def parse_beam_search(pred, ll, link):\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    G.add_node((0, 0), label=detokenizer_ja[bos_id_ja], weight=0)\n",
    "    for t in range(len(pred)):\n",
    "        for k in range(K):\n",
    "            prev_node = (t, link[t,k])\n",
    "            if (prev_node not in G) or (G.nodes[prev_node]['label'] == detokenizer_ja[eos_id_ja]):\n",
    "                continue\n",
    "            G.add_node((t+1, k), label=detokenizer_ja[pred[t,k]], weight=G.nodes[prev_node]['weight']+ll[t,k])\n",
    "            G.add_edge(prev_node, (t+1, k), weight=ll[t, k], label=ll[t, k])\n",
    "    \n",
    "    pos = hierarchy_pos(G, (0, 0))\n",
    "    #pos = nx.nx_agraph.graphviz_layout(G, prog='dot', args=\"-Grankdir=LR\")\n",
    "    \n",
    "    leaf = [v for v, l in G.nodes(data='label') if l == detokenizer_ja[eos_id_ja]]\n",
    "    leaf = {v: G.nodes[v]['weight'] for v in leaf}\n",
    "    path = nx.shortest_path(G, source=(0, 0), target=sorted(leaf.items(), key=lambda x: -x[1])[0][0])\n",
    "\n",
    "    plt.figure(figsize=(20,10))\n",
    "    node_size = 700\n",
    "    \n",
    "    # nodes\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=[v for v in G.nodes if v not in path], node_color='c', node_size=node_size)\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=path, node_color='r', node_size=node_size)\n",
    "    nx.draw_networkx_labels(G, pos, nx.get_node_attributes(G, 'label'), font_family='TakaoPGothic', font_size=12)\n",
    "\n",
    "    # edges\n",
    "    nx.draw_networkx_edges(G, pos, node_size = node_size)\n",
    "    edge_labels = {(u, v): format(G[u][v]['label'], '.3f') for u, v in G.edges}\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels, font_size=10)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "parse_beam_search(y_pred[num], ll[num], link[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
