{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第7回講義 宿題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題\n",
    "\n",
    "今Lessonで学んだことに工夫を加えて、CNNでより高精度なCIFAR10の分類器を実装してみましょう。精度上位者はリーダーボードに載ります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目標値\n",
    "\n",
    "Accuracy 78%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ルール\n",
    "\n",
    "- 訓練データはx_train、 t_train、テストデータはx_testで与えられます。\n",
    "- 予測ラベルは one_hot表現ではなく0~9のクラスラベル で表してください。\n",
    "- **下のセルで指定されているx_train、t_train以外の学習データは使わないでください。**\n",
    "- ネットワークの形などは特に制限を設けません。\n",
    "- 高レベルのAPI(tf.layers)を利用しても構いません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提出方法\n",
    "\n",
    "- 2つのファイルを提出していただきます。\n",
    "  - テストデータ (x_test) に対する予測ラベルをcsvファイル (ファイル名: submission_pred.csv) で提出してください。\n",
    "  - それに対応するpythonのコードをsubmission_code.pyとして提出してください (%%writefileコマンドなどを利用してください)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価方法\n",
    "\n",
    "- 予測ラベルのt_testに対する精度 (Accuracy) で評価します。\n",
    "- 毎日夜24時にテストデータの一部に対する精度でLeader Boardを更新します。\n",
    "- 締切日の夜24時にテストデータ全体に対する精度でLeader Boardを更新します。これを最終的な評価とします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み込み\n",
    "\n",
    "- この部分は修正しないでください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_cifar10():\n",
    "    \n",
    "    # 学習データ\n",
    "    x_train = np.load('/root/userspace/public/chap07/data/x_train.npy')\n",
    "    t_train = np.load('/root/userspace/public/chap07/data/t_train.npy')\n",
    "\n",
    "    # テストデータ\n",
    "    x_test = np.load('/root/userspace/public/chap07/data/x_test.npy')\n",
    "    \n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "    \n",
    "    t_train = np.eye(10)[t_train.astype('int32').flatten()]\n",
    "    \n",
    "    return (x_train, x_test, t_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 畳み込みニューラルネットワーク(CNN)の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%writefile /root/userspace/submission_code.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "random_state = 42\n",
    "\n",
    "def tf_log(x):\n",
    "    # WRITE ME\n",
    "\n",
    "### ネットワーク ###\n",
    "tf.reset_default_graph()\n",
    "is_training = tf.placeholder(tf.bool, shape=())\n",
    "\n",
    "# WRITE ME\n",
    "\n",
    "y = # WRITE ME\n",
    "\n",
    "cost = - tf.reduce_mean(tf.reduce_sum(t * tf_log(y), axis=1))\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer = tf.train.AdamOptimizer(0.01).minimize(cost)\n",
    "\n",
    "### 前処理 ###\n",
    "def gcn(x):\n",
    "    # WRITE ME\n",
    "\n",
    "class ZCAWhitening:\n",
    "    # WRITE ME\n",
    "    \n",
    "x_train, x_test, t_train = load_cifar10()\n",
    "x_train, x_valid, t_train, t_valid = train_test_split(x_train, t_train, test_size=0.1, random_state=random_state)\n",
    "zca = ZCAWhitening()\n",
    "zca.fit(x_train)\n",
    "x_train_zca = zca.transform(gcn(x_train))\n",
    "t_train_zca = t_train[:]\n",
    "x_valid_zca = zca.transform(gcn(x_valid))\n",
    "t_valid_zca = t_valid[:]\n",
    "x_test_zca = zca.transform(gcn(x_test))\n",
    "\n",
    "### 学習 ###\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = x_train.shape[0]//batch_size\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # WRITE ME\n",
    "sess.close()\n",
    "\n",
    "y_pred = # WRITE ME\n",
    "submission = pd.Series(y_pred, name='label')\n",
    "submission.to_csv('/root/userspace/submission_pred.csv', header=True, index_label='id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
