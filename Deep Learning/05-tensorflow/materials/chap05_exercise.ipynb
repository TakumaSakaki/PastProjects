{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5回講義 演習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "#sys.path.insert(0, '/root/userspace/public/chap05/materials')\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "random_seed = 34\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "tf.set_random_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目次\n",
    "\n",
    "課題. TensorFlowを学ぶ\n",
    "1. TensorFlow概観\n",
    "2. TensorFlow基礎\n",
    "    - 2.1. `Placeholder`・`Variable`\n",
    "    - 2.2. 行列・テンソル\n",
    "    - 2.3. 数学\n",
    "    - 2.4. 制御構文\n",
    "    - 2.5. 勾配 (微分) の計算\n",
    "    - 2.6. 変数の値の更新\n",
    "3. TensorFlow応用\n",
    "    - 3.1. TensorBoardによるグラフの表示\n",
    "    - 3.2. グラフの管理と整理\n",
    "    - 3.3. モデルの保存・読み込み\n",
    "    - 3.4. メモリの管理\n",
    "    - 3.5. `tf.data.Dataset`の利用\n",
    "4. TensorFlowによるニューラルネットワークの実装\n",
    "    - 4.1. Optimizer\n",
    "    - 4.2. 正則化 (重み減衰)\n",
    "    - 4.3. Dropout\n",
    "    - 4.4. MLP (`tf.data.Dataset`を使用しない版)\n",
    "    - 4.5. MLP (`tf.data.Dataset`を使用する版)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題. TensorFlowを学ぶ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TensorFlow概観"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf`では、基本的に以下の流れで機械学習モデルを構築していきます。\n",
    "\n",
    "1. `Placeholder`と`Variable`の設定\n",
    "2. グラフの構築\n",
    "3. 誤差関数の設定\n",
    "4. 重みの更新ルールの設定\n",
    "5. `tf.Session()`を開始して学習\n",
    "6. 予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下にロジスティック回帰 (OR) の例を示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ (OR)\n",
    "x_data = np.array([[0, 1], [1, 0], [0, 0], [1, 1]]).astype(np.float32)\n",
    "t_data = np.array([[1], [1], [0], [1]]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/takuma.s/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/takuma.s/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "EPOCH: 100, Train Cost, 0.156\n",
      "EPOCH: 200, Train Cost, 0.090\n",
      "EPOCH: 300, Train Cost, 0.062\n",
      "EPOCH: 400, Train Cost, 0.047\n",
      "EPOCH: 500, Train Cost, 0.038\n",
      "EPOCH: 600, Train Cost, 0.032\n",
      "EPOCH: 700, Train Cost, 0.027\n",
      "EPOCH: 800, Train Cost, 0.024\n",
      "EPOCH: 900, Train Cost, 0.021\n",
      "EPOCH: 1000, Train Cost, 0.019\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9835751 ],\n",
       "       [0.9835756 ],\n",
       "       [0.04120126],\n",
       "       [0.99998796]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1. Placeholder・Variableの設定\n",
    "## Placeholder: データを流し込む変数. データ毎に変わる\n",
    "x = tf.placeholder(dtype=tf.float32, shape=(None, 2), name='x')\n",
    "t = tf.placeholder(dtype=tf.float32, shape=(None, 1), name='t')\n",
    "\n",
    "## Variable: 変数 (重み). データ間で共有される\n",
    "W = tf.Variable(tf.random_uniform(shape=(2, 1), minval=-0.08, maxval=0.08, dtype=tf.float32), name='W')\n",
    "b = tf.Variable(tf.zeros(shape=(1), dtype=tf.float32), name='b')\n",
    "\n",
    "# Step 2. グラフの構築\n",
    "y = tf.nn.sigmoid(tf.matmul(x, W) + b)\n",
    "\n",
    "# Step 3. 誤差関数の設定\n",
    "cost = - tf.reduce_mean(tf.reduce_sum(t * tf.log(y) + (1 - t) * tf.log(1 - y), axis=1))\n",
    "\n",
    "# Step 4. 重みの更新ルールの設定\n",
    "gW, gb = tf.gradients(cost, [W, b]) # 勾配の計算\n",
    "updates = [\n",
    "    W.assign_sub(0.5 * gW), # 勾配降下法\n",
    "    b.assign_sub(0.5 * gb)\n",
    "]\n",
    "train = tf.group(*updates)\n",
    "\n",
    "# Step 5. tf.Session()を開始して学習\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) # 重み (Variable) の初期化\n",
    "for epoch in range(1000):\n",
    "    cost_, _ = sess.run([cost, train], feed_dict={x: x_data, t: t_data})\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print('EPOCH: {}, Train Cost, {:.3f}'.format(epoch + 1, cost_))\n",
    "\n",
    "# Step 6. 予測\n",
    "print()\n",
    "y_pred = sess.run(y, feed_dict={x: x_data})\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TensorFlow基礎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. `Placeholder`・`Variable`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tfには2種類の変数 (のようなもの) があります。それぞれ以下のように使い分けます。\n",
    "\n",
    "- `tf.placeholder`: データ間で値が共有されない変数 (入力の`x`、正解ラベルの `t` などに使用)\n",
    "- `tf.Variable` : データ間で値が共有される変数 (重みの `W`、`b` など更新されるものに使用）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1. `tf.placeholder`\n",
    "\n",
    "データを流し込む入り口として使います。\n",
    "- 変数の型 (`tf.int32`、`tf.float32`) を指定する必要があります。\n",
    "- 実行時にはデータを`feed_dict`で渡す必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "y = x**2\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(y, feed_dict={x: 3}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shapeが決まっている場合はそれをリストで指定することもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.94555587e-02 5.58484495e-01 2.43727374e+00 2.15530962e-01]\n",
      " [1.23947896e-01 1.64222145e+00 8.36940557e-02 9.60455894e-01]\n",
      " [2.28411570e-01 2.03236982e-01 5.66171110e-01 2.60683537e-01]\n",
      " [4.98086065e-01 1.80045128e-01 5.38992546e-02 3.29473495e+00]\n",
      " [4.38797522e+00 1.07320511e+00 2.05675960e+00 7.74112120e-02]\n",
      " [3.54197435e-03 1.71168077e+00 1.65457277e-06 1.59023929e+00]\n",
      " [3.47166322e-02 2.04469323e+00 6.25842333e-01 8.86486322e-02]\n",
      " [9.25347030e-01 1.14584315e+00 1.45315349e+00 4.14775521e-01]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=(None, 4))\n",
    "\n",
    "y = x**2\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(y, feed_dict={x: np.random.randn(8, 4)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. `tf.Variable`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "値がデータ間で共有されるので、まず初期値を与える必要があります。\n",
    "\n",
    "- 全ての変数を初期化する場合は`tf.global_variables_initializer()`を使います。\n",
    "- 個別に変数を初期化する場合は`tf.variables_initializer()`を使い、引数に初期化したい変数をリストで渡します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(1.0, name='w')\n",
    "b = tf.Variable(0.0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "#     sess.run(tf.variables_initializer([w, b])) # こちらでも可\n",
    "    \n",
    "    print(w.eval()) # print(sess.run(w))でも同じです\n",
    "    print(b.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = tf.Variable(0.0)\n",
    "# b = tf.Variable(1.0)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.variables_initializer([w]))\n",
    "#     print(w.eval()) \n",
    "#     print(b.eval()) # 初期化していないので、エラーが出ます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. 行列・テンソル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1. 生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本的な行列は、NumPyと同様の関数を使って作ることが可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# tf.constant:\n",
      "9\n",
      "\n",
      "# tf.ones:\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "# tf.zeros:\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "# tf.fill:\n",
      "[[99 99 99]\n",
      " [99 99 99]]\n",
      "\n",
      "# tf.eye:\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "\n",
      "# tf.ones_like:\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "\n",
      "# tf.zeros_like:\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# スカラー\n",
    "x_constant = tf.constant(value=9)\n",
    "\n",
    "# 全要素が1の行列\n",
    "x_ones = tf.ones((2, 3))\n",
    "\n",
    "# 全要素が0の行列\n",
    "x_zeros = tf.zeros((2, 3))\n",
    "\n",
    "# 指定した値で満たされた行列\n",
    "x_fill = tf.fill(dims=(2, 3), value=99)\n",
    "\n",
    "# 単位行列\n",
    "x_eye = tf.eye(2)\n",
    "\n",
    "# 渡された変数と同じshapeのtf.ones\n",
    "x_ones_like = tf.ones_like(tensor=x_eye)\n",
    "\n",
    "# 渡された変数と同じshapeのtf.zeros\n",
    "x_zeros_like = tf.zeros_like(tensor=x_eye)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('# tf.constant:')\n",
    "    print(sess.run(x_constant))\n",
    "    print()\n",
    "    \n",
    "    print('# tf.ones:')\n",
    "    print(sess.run(x_ones))\n",
    "    print()\n",
    "    \n",
    "    print('# tf.zeros:')\n",
    "    print(sess.run(x_zeros))\n",
    "    print()\n",
    "    \n",
    "    print('# tf.fill:')\n",
    "    print(sess.run(x_fill))\n",
    "    print()\n",
    "\n",
    "    print('# tf.eye:')\n",
    "    print(sess.run(x_eye))\n",
    "    print()\n",
    "\n",
    "    print('# tf.ones_like:')\n",
    "    print(sess.run(x_ones_like))\n",
    "    print()\n",
    "\n",
    "    print('# tf.zeros_like:')\n",
    "    print(sess.run(x_zeros_like))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これらを`Variable`の初期値として利用することも可能です。また代わりにNumPyのarrayを初期値として与えることも可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.65697956  0.9696641   0.42789015]\n",
      " [ 0.8992823  -0.42343983 -0.84637344]]\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal((2, 3)), name='w')\n",
    "b = tf.Variable(np.zeros(3), name='b') # tf.zeros(3)でもOK\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print(W.eval())\n",
    "    print(b.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2. 乱数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般的な乱数は大体揃っています.\n",
    "\n",
    "乱数のシードはグローバルに`tf.set_random_seed`で指定するか、個別にseedオプションで指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-fd750c05fccc>:12: Bernoulli.__init__ (from tensorflow.python.ops.distributions.bernoulli) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /Users/takuma.s/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorflow/python/ops/distributions/bernoulli.py:97: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "# randn:\n",
      "[[ 0.49384186  0.91458374 -0.63111424]\n",
      " [-1.3303034  -1.2144839   0.04439415]]\n",
      "\n",
      "# uniform:\n",
      "[[0.5487499  0.13401854 0.70727   ]\n",
      " [0.04730201 0.74189115 0.40300822]]\n",
      "\n",
      "# bernoulli:\n",
      "[1 0 0 0 1 0 1 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# seedはグラフレベルでリセットされるので, グラフの初期化も必要. (グラフの初期化については後述)\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(34)\n",
    "\n",
    "# 正規分布\n",
    "x_randn = tf.random_normal(shape=(2, 3), mean=0.0, stddev=1.0, seed=34) # seedはseedで指定\n",
    "\n",
    "# 一様分布\n",
    "x_uniform = tf.random_uniform(shape=(2, 3), minval=0, maxval=1)\n",
    "\n",
    "# ベルヌーイ分布\n",
    "x_bernoulli = tf.distributions.Bernoulli(probs=0.5).sample(sample_shape=(10))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('# randn:')\n",
    "    print(sess.run(x_randn))\n",
    "    print()\n",
    "    \n",
    "    print('# uniform:')\n",
    "    print(sess.run(x_uniform))\n",
    "    print()\n",
    "    \n",
    "    print('# bernoulli:')\n",
    "    print(sess.run(x_bernoulli))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3. shapeの確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "グラフ上の変数のshapeは`tf.shape`で取得することができます。例えば入力データのshapeに合わせて乱数を発生させたいときなどに使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# xのshape:\n",
      "[2 3]\n",
      "\n",
      "# normal 1:\n",
      "[[ 0.6309411   0.6158685  -1.4873706 ]\n",
      " [-0.13940305 -0.36543897  0.5966492 ]]\n",
      "\n",
      "# normal 2:\n",
      "[[ 1.0934397   1.2373759 ]\n",
      " [-0.02992922  1.0451084 ]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, name='x')\n",
    "\n",
    "x_shape = tf.shape(x)\n",
    "\n",
    "x_randn = tf.random_normal(shape=x_shape)\n",
    "\n",
    "x_data = np.empty((2, 3))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('# xのshape:')\n",
    "    print(sess.run(x_shape, feed_dict={x: x_data}))\n",
    "    print()\n",
    "    \n",
    "    print('# normal 1:')\n",
    "    print(sess.run(x_randn, feed_dict={x: x_data}))\n",
    "    print()\n",
    "    \n",
    "    print('# normal 2:')\n",
    "    print(sess.run(x_randn, feed_dict={x: x_data[:, :2]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4. 変形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# x:\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "# tf.expand_dims:\n",
      "[[[1.]\n",
      "  [1.]\n",
      "  [1.]]\n",
      "\n",
      " [[1.]\n",
      "  [1.]\n",
      "  [1.]]]\n",
      "\n",
      "# tf.transpose:\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n",
      "\n",
      "# tf.reshape:\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "\n",
      "# tf.tile:\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "# tf.split:\n",
      "[array([[1., 1., 1.]], dtype=float32), array([[1., 1., 1.]], dtype=float32)]\n",
      "\n",
      "# tf.concat\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 全要素が1の行列\n",
    "x = tf.ones((2, 3))\n",
    "\n",
    "# 次元の追加: 指定したaxisに新たに次元を追加\n",
    "x_expand_dims = tf.expand_dims(x, axis=2) # x[:, :, None], x[:, :, tf.newaxis] でも同じ\n",
    "\n",
    "# 次元の入れ替え\n",
    "x_transpose = tf.transpose(x, perm=(1, 0))\n",
    "\n",
    "# 変形\n",
    "x_reshape = tf.reshape(x, shape=(6, 1))\n",
    "\n",
    "# 繰り返し\n",
    "x_tile = tf.tile(input=x, multiples=(2, 1))\n",
    "\n",
    "# 分割: axisに沿って変数をnum_or_size_splits個に分割\n",
    "x_split1, x_split2 = tf.split(value=x, num_or_size_splits=2, axis=0)\n",
    "\n",
    "# 連結\n",
    "x_concat = tf.concat([x_split1, x_split2], axis=0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('# x:')\n",
    "    print(sess.run(x))\n",
    "    print()\n",
    "    \n",
    "    print('# tf.expand_dims:')\n",
    "    print(sess.run(x_expand_dims))\n",
    "    print()\n",
    "    \n",
    "    print('# tf.transpose:')\n",
    "    print(sess.run(x_transpose))\n",
    "    print()\n",
    "    \n",
    "    print('# tf.reshape:')\n",
    "    print(sess.run(x_reshape))\n",
    "    print()\n",
    "    \n",
    "    print('# tf.tile:')\n",
    "    print(sess.run(x_tile))\n",
    "    print()\n",
    "    \n",
    "    print('# tf.split:')\n",
    "    print(sess.run([x_split1, x_split2]))\n",
    "    print()\n",
    "    \n",
    "    print('# tf.concat')\n",
    "    print(sess.run(x_concat))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5. 行列・テンソル積"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np` の `dot`、`matmul` に対応するものは `tf.matmul` ですが、少し挙動が違うので注意する必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 行列積"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.matmul`もしくは`@`を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 3. 3. 3.]\n",
      " [3. 3. 3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones((2, 3))\n",
    "b = tf.ones((3, 4))\n",
    "\n",
    "c = tf.matmul(a, b) # a @ b でも可\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(c.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ベクトルに対しても `None` などで明示的に行列に変換する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones((2,2))\n",
    "b = tf.ones(2)\n",
    "\n",
    "# c = tf.matmul(a, b) # エラー\n",
    "c = tf.matmul(a, b[:, None])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(c.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.6. テンソル積"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np`と同様に`tf`にも`einsum`があります。3階以上のテンソルを含む計算はこれを用いるのがわかりやすくベターです"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 6. 6. 6.]\n",
      "24.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones((2,3,4))\n",
    "b = tf.ones((2,3))\n",
    "\n",
    "c = tf.einsum('ijk,ij->k', a, b)\n",
    "c_sum = tf.einsum('ijk,ij->', a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(c.eval())\n",
    "    print(c_sum.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. 数学"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1. スカラー演算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APIはNumPyと非常に似ています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03856168 0.78010046]\n",
      "\n",
      "# exp:\n",
      "[1.0393149 2.1816914]\n",
      "\n",
      "# log:\n",
      "[-3.2554963  -0.24833256]\n",
      "\n",
      "# sqrt:\n",
      "[0.19637127 0.88323295]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(34)\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "x_exp = tf.exp(x)\n",
    "x_log = tf.log(x)\n",
    "x_sqrt = tf.sqrt(x)\n",
    "\n",
    "x_data = np.random.random(2)\n",
    "print(x_data)\n",
    "print()\n",
    "with tf.Session() as sess:\n",
    "    print('# exp:')\n",
    "    print(sess.run(x_exp, feed_dict={x: x_data}))\n",
    "    print()\n",
    "    \n",
    "    print('# log:')\n",
    "    print(sess.run(x_log, feed_dict={x: x_data}))\n",
    "    print()\n",
    "    \n",
    "    print('# sqrt:')\n",
    "    print(sess.run(x_sqrt, feed_dict={x: x_data}))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークなどで使われる活性化関数は`tf.nn`以下にあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-e4d6fff29a7e>:14: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "# x:\n",
      "[[0.80184854 0.51211231 0.07866238]\n",
      " [0.03415976 0.56615131 0.14967356]]\n",
      "\n",
      "# sigmoid:\n",
      "[[0.6903697  0.6253015  0.51965547]\n",
      " [0.5085391  0.63787466 0.5373487 ]]\n",
      "\n",
      "# tanh:\n",
      "[[0.665069   0.4715894  0.07850052]\n",
      " [0.03414648 0.51252717 0.14856581]]\n",
      "\n",
      "# relu:\n",
      "[[0.80184853 0.5121123  0.07866238]\n",
      " [0.03415976 0.5661513  0.14967357]]\n",
      "\n",
      "# elu:\n",
      "[[0.80184853 0.5121123  0.07866238]\n",
      " [0.03415976 0.5661513  0.14967357]]\n",
      "\n",
      "# softplus:\n",
      "[[1.1723764 0.9816336 0.7332517]\n",
      " [0.7103729 1.0157648 0.7707817]]\n",
      "\n",
      "# softmax:\n",
      "[[0.44769472 0.33508205 0.21722321]\n",
      " [0.26145372 0.44507766 0.2934687 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "x_sigmoid = tf.nn.sigmoid(x)\n",
    "\n",
    "x_tanh = tf.nn.tanh(x) # tf.tanhでも可\n",
    "\n",
    "x_relu = tf.nn.relu(x)\n",
    "\n",
    "x_elu = tf.nn.elu(x)\n",
    "\n",
    "x_softplus = tf.nn.softplus(x)\n",
    "\n",
    "# 正規化したい軸を指定する (ver. 1.4以前はdim、ver. 1.5以降ではaxis)。最後の軸に対して行いたいときは-1\n",
    "x_softmax = tf.nn.softmax(x, dim=-1)\n",
    "\n",
    "x_data = np.random.random((2, 3))\n",
    "print('# x:')\n",
    "print(x_data)\n",
    "print()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print('# sigmoid:')\n",
    "    print(sess.run(x_sigmoid, feed_dict={x: x_data}))\n",
    "    print()\n",
    "    \n",
    "    print('# tanh:')\n",
    "    print(sess.run(x_tanh, feed_dict={x: x_data}))\n",
    "    print()\n",
    "    \n",
    "    print('# relu:')\n",
    "    print(sess.run(x_relu, feed_dict={x: x_data}))\n",
    "    print()\n",
    "\n",
    "    print('# elu:')\n",
    "    print(sess.run(x_elu, feed_dict={x: x_data}))\n",
    "    print()\n",
    "    \n",
    "    print('# softplus:')\n",
    "    print(sess.run(x_softplus, feed_dict={x: x_data}))\n",
    "    print()\n",
    "\n",
    "    print('# softmax:')\n",
    "    print(sess.run(x_softmax, feed_dict={x: x_data}))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2. 集約演算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引数`axis`で指定した軸に沿って演算を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# x:\n",
      "[[ 0.7848821  -1.5550356  -0.17887385]\n",
      " [-0.14428262 -0.28336897 -0.37591296]]\n",
      "\n",
      "# 合計:\n",
      "[ 0.6405995 -1.8384045 -0.5547868]\n",
      "\n",
      "# 平均:\n",
      "[ 0.32029974 -0.91920227 -0.2773934 ]\n",
      "\n",
      "# 分散:\n",
      "[0.2158368  0.40428397 0.0097061 ]\n",
      "\n",
      "# 最大値:\n",
      "[ 0.7848821  -0.28336897 -0.17887385]\n",
      "\n",
      "# 最小値:\n",
      "[-0.14428262 -1.5550356  -0.37591296]\n",
      "\n",
      "# 最大値のindex:\n",
      "[0 1 0]\n",
      "\n",
      "# 最小値のindex:\n",
      "[1 0 1]\n",
      "\n",
      "# ノルム:\n",
      "[0.7980335  1.5806434  0.41630086]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.random_normal((2, 3))\n",
    "\n",
    "x_sum = tf.reduce_sum(x, axis=0)\n",
    "\n",
    "# 平均, 分散\n",
    "x_mean, x_var = tf.nn.moments(x, axes=0) # 平均はtf.reduce_meanでも可\n",
    "\n",
    "# 最大値\n",
    "x_max = tf.reduce_max(input_tensor=x, axis=0)\n",
    "\n",
    "# 最小値\n",
    "x_min = tf.reduce_min(input_tensor=x, axis=0)\n",
    "\n",
    "# 最大値のindex\n",
    "x_argmax = tf.argmax(input=x, axis=0)\n",
    "\n",
    "# 最小値のindex\n",
    "x_argmin = tf.argmin(input=x, axis=0)\n",
    "\n",
    "# ノルム\n",
    "x_norm = tf.norm(tensor=x, ord=2, axis=0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x_, x_sum_, x_mean_, x_var_, x_max_, x_min_, x_argmax_, x_argmin_, x_norm_ = sess.run(\n",
    "        [x, x_sum, x_mean, x_var, x_max, x_min, x_argmax, x_argmin, x_norm])\n",
    "    \n",
    "    print('# x:')\n",
    "    print(x_)\n",
    "    print()\n",
    "    \n",
    "    print('# 合計:')\n",
    "    print(x_sum_)\n",
    "    print()\n",
    "    \n",
    "    print('# 平均:')\n",
    "    print(x_mean_)\n",
    "    print()\n",
    "    \n",
    "    print('# 分散:')\n",
    "    print(x_var_)\n",
    "    print()\n",
    "\n",
    "    print('# 最大値:')\n",
    "    print(x_max_)\n",
    "    print()\n",
    "    \n",
    "    print('# 最小値:')\n",
    "    print(x_min_)\n",
    "    print()\n",
    "    \n",
    "    print('# 最大値のindex:')\n",
    "    print(x_argmax_)\n",
    "    print()\n",
    "    \n",
    "    print('# 最小値のindex:')\n",
    "    print(x_argmin_)\n",
    "    print()\n",
    "    \n",
    "    print('# ノルム:')\n",
    "    print(x_norm_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. 制御構文"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1. 条件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常のPythonの`if`に対応するものは`tf.cond`です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "50.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, name='x')\n",
    "y = tf.placeholder(tf.float32, name='y')\n",
    "\n",
    "absl = tf.cond(\n",
    "    pred=x > y,\n",
    "    true_fn=lambda: x - y,\n",
    "    false_fn=lambda: y - x\n",
    ")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(absl, feed_dict={x: 100, y:  50}))\n",
    "    print(sess.run(absl, feed_dict={x:  50, y: 100}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変数の各要素に対して条件付ける場合は`tf.where`を使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# x:\n",
      "[[-0.3263399  -0.7688404   1.7880154 ]\n",
      " [-1.8622565  -0.58020264  0.6365889 ]]\n",
      "\n",
      "# tf.where(x):\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.random_normal((2, 3))\n",
    "\n",
    "x_where = tf.where(\n",
    "    condition=x > 0,\n",
    "    x=tf.ones_like(x),\n",
    "    y=tf.zeros_like(x)\n",
    ")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x_, x_where_ = sess.run([x, x_where])\n",
    "    \n",
    "    print('# x:')\n",
    "    print(x_)\n",
    "    print()\n",
    "    \n",
    "    print('# tf.where(x):')\n",
    "    print(x_where_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変数を一定の値でclipしたい場合は`tf.clip_by_value`を使います。例えばlogの中身が0になるのを防ぐときなどに使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# x:\n",
      "[[ 1.51674     2.0579255   0.44247675]\n",
      " [ 1.801229    0.10361186 -0.41155642]]\n",
      "\n",
      "# tf_log(x):\n",
      "[[  0.41656327   0.7216984   -0.81536734]\n",
      " [  0.5884692   -2.2671034  -16.118095  ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.random_normal((2, 3))\n",
    "\n",
    "x_log = tf.log(tf.clip_by_value(t=x, clip_value_min=1e-7, clip_value_max=x))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x_, x_log_ = sess.run([x, x_log])\n",
    "    \n",
    "    print('# x:')\n",
    "    print(x_)\n",
    "    print()\n",
    "    \n",
    "    print('# tf_log(x):')\n",
    "    print(x_log_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.log`などよく使うものは関数化しておくと便利です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_log(x):\n",
    "    return tf.log(tf.clip_by_value(x, 1e-10, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2. 比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比較演算子は\n",
    "- `tf.equal`\n",
    "- `tf.not_equal`\n",
    "- `tf.greater`\n",
    "- `tf.less`\n",
    "\n",
    "などを使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "50.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, name='x')\n",
    "y = tf.placeholder(tf.float32, name='y')\n",
    "\n",
    "absl = tf.cond(\n",
    "    pred=tf.greater(x, y),\n",
    "    true_fn=lambda: x - y,\n",
    "    false_fn=lambda: y - x\n",
    ")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(absl, feed_dict={x: 100, y:  50}))\n",
    "    print(sess.run(absl, feed_dict={x:  50, y: 100}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "他の言語の`for`、`while`に対応するものはそれぞれ`tf.scan`、`tf.while_loop`です。これはRNNの回で詳細に扱います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. 勾配 (微分) の計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.gradients`をつかうことで微分を計算することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0]\n",
      "[4.0]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, name='x')\n",
    "y = x**2\n",
    "\n",
    "grads = tf.gradients(y, x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(grads, feed_dict={x: 1.}))\n",
    "    print(sess.run(grads, feed_dict={x: 2.}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二引数(`xs`)に複数の変数を指定すると、それぞれに対する偏微分をリストで返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.0, 64.0]\n",
      "[18.0, 512.0]\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.placeholder(tf.float32, name='x1')\n",
    "x2 = tf.placeholder(tf.float32, name='x2')\n",
    "y = 3*x1**2 + 2*x2**4\n",
    "\n",
    "grads = tf.gradients(y, [x1, x2])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(grads, feed_dict={x1: 1, x2: 2}))\n",
    "    print(sess.run(grads, feed_dict={x1: 3, x2: 4}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. 変数の値の更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Variable`の値を更新するには `assign`、`assign_add`、`assign_sub`を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(0.0, name='w')\n",
    "\n",
    "increment_a = a.assign_add(1.)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        print(sess.run(increment_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "複数の更新をまとめる場合は `tf.group` を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 1.0,  b: 9.0\n",
      "a: 2.0,  b: 8.0\n",
      "a: 3.0,  b: 7.0\n",
      "a: 4.0,  b: 6.0\n",
      "a: 5.0,  b: 5.0\n",
      "a: 6.0,  b: 4.0\n",
      "a: 7.0,  b: 3.0\n",
      "a: 8.0,  b: 2.0\n",
      "a: 9.0,  b: 1.0\n",
      "a: 10.0,  b: 0.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(0.0, name='a')\n",
    "b = tf.Variable(10.0, name='b')\n",
    "\n",
    "increment_a = a.assign_add(1.)\n",
    "decrement_b = b.assign_sub(1.)\n",
    "\n",
    "updates = [\n",
    "    increment_a,\n",
    "    decrement_b\n",
    "]\n",
    "\n",
    "update = tf.group(*updates)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        sess.run(update)\n",
    "        print('a:', a.eval(), end=',  ')\n",
    "        print('b:', b.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更新に順序をつけたい場合は`tf.control_dependencies`を利用します。\n",
    "\n",
    "Optimizerを実装するときなどに使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "25\n",
      "676\n",
      "458329\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "a = tf.Variable(0, name='a')\n",
    "\n",
    "increment_a = a.assign_add(1)\n",
    "with tf.control_dependencies([increment_a]):\n",
    "    square_a = a.assign(a * a)\n",
    "\n",
    "update = tf.group(*[increment_a, square_a])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(5):\n",
    "        sess.run(update)\n",
    "        print(sess.run(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TensorFlow応用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. TensorBoardによるグラフの表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowで計算グラフの構築方法を扱ってきましたが、ここでは構築した計算グラフの可視化をし、視覚的に捉えてみましょう。\n",
    "\n",
    "計算グラフを表示するには、`tensorboard.py` を読み込む必要があります。\n",
    "\n",
    "tensorboard.pyをimportしたら、show_graph関数にグラフを渡すことで可視化できます。\n",
    "\n",
    "可視化結果はインタラクティブな表示になるので、拡大や移動、詳細表示等を試してみましょう。\n",
    "\n",
    "出典: jupyter上に、tensorBoardのグラフを表示させる\n",
    ": https://qiita.com/kegamin/items/887c7dfe8bbb76197741 (2018年9月20日参照)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.24123302122509915&quot;).pbtxt = 'node {\\n  name: &quot;random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\002\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 34\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 34\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_normal/RandomStandardNormal&quot;\\n  input: &quot;random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_normal/mul&quot;\\n  input: &quot;random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\002\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 34\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 9\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;random_uniform/max&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_uniform/RandomUniform&quot;\\n  input: &quot;random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_uniform/mul&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/probs&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.5\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/logits/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;Bernoulli/probs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/logits/mul/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/logits/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Bernoulli/logits/mul/x&quot;\\n  input: &quot;Bernoulli/probs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/logits/Log1p&quot;\\n  op: &quot;Log1p&quot;\\n  input: &quot;Bernoulli/logits/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/logits/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Bernoulli/logits/Log&quot;\\n  input: &quot;Bernoulli/logits/Log1p&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/sample_shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/sample_shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/batch_shape_tensor/batch_shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/concat/values_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Bernoulli/sample/concat/values_0&quot;\\n  input: &quot;Bernoulli/batch_shape_tensor/batch_shape&quot;\\n  input: &quot;Bernoulli/sample/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;Bernoulli/sample/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 34\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 27\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Bernoulli/sample/random_uniform/max&quot;\\n  input: &quot;Bernoulli/sample/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Bernoulli/sample/random_uniform/RandomUniform&quot;\\n  input: &quot;Bernoulli/sample/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Bernoulli/sample/random_uniform/mul&quot;\\n  input: &quot;Bernoulli/sample/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;Bernoulli/sample/random_uniform&quot;\\n  input: &quot;Bernoulli/probs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;Bernoulli/sample/Less&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;Bernoulli/sample/Shape&quot;\\n  input: &quot;Bernoulli/sample/strided_slice/stack&quot;\\n  input: &quot;Bernoulli/sample/strided_slice/stack_1&quot;\\n  input: &quot;Bernoulli/sample/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;Bernoulli/sample/sample_shape_1&quot;\\n  input: &quot;Bernoulli/sample/strided_slice&quot;\\n  input: &quot;Bernoulli/sample/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Bernoulli/sample/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Bernoulli/sample/Cast&quot;\\n  input: &quot;Bernoulli/sample/concat_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;x&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;x&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_1/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_1/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_1/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 34\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 45\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_1/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_normal_1/RandomStandardNormal&quot;\\n  input: &quot;random_normal_1/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_normal_1/mul&quot;\\n  input: &quot;random_normal_1/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n          dim {\\n            size: 3\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;ones&quot;\\n  input: &quot;ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;transpose/perm&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;ones&quot;\\n  input: &quot;transpose/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\006\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;ones&quot;\\n  input: &quot;Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Tile/multiples&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\002\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;ones&quot;\\n  input: &quot;Tile/multiples&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;split/split_dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;split&quot;\\n  op: &quot;Split&quot;\\n  input: &quot;split/split_dim&quot;\\n  input: &quot;ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;num_split&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;split&quot;\\n  input: &quot;split:1&quot;\\n  input: &quot;concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ones_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n          dim {\\n            size: 3\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ones_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n          dim {\\n            size: 4\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;ones_1&quot;\\n  input: &quot;ones_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ones_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n          dim {\\n            size: 2\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ones_4/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ones_4/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ones_4&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;ones_4/shape_as_tensor&quot;\\n  input: &quot;ones_4/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;ones_4&quot;\\n  input: &quot;strided_slice/stack&quot;\\n  input: &quot;strided_slice/stack_1&quot;\\n  input: &quot;strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;ones_3&quot;\\n  input: &quot;strided_slice&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sigmoid&quot;\\n  op: &quot;Sigmoid&quot;\\n  input: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Tanh&quot;\\n  op: &quot;Tanh&quot;\\n  input: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Elu&quot;\\n  op: &quot;Elu&quot;\\n  input: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Softplus&quot;\\n  op: &quot;Softplus&quot;\\n  input: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Softmax&quot;\\n  op: &quot;Softmax&quot;\\n  input: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_2/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\002\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_2/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_2/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_2/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;random_normal_2/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 34\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 84\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_2/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_normal_2/RandomStandardNormal&quot;\\n  input: &quot;random_normal_2/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_normal_2&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_normal_2/mul&quot;\\n  input: &quot;random_normal_2/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;random_normal_2&quot;\\n  input: &quot;Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;moments/mean/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;moments/mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;random_normal_2&quot;\\n  input: &quot;moments/mean/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;moments/StopGradient&quot;\\n  op: &quot;StopGradient&quot;\\n  input: &quot;moments/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;moments/SquaredDifference&quot;\\n  op: &quot;SquaredDifference&quot;\\n  input: &quot;random_normal_2&quot;\\n  input: &quot;moments/StopGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;moments/variance/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;moments/variance&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;moments/SquaredDifference&quot;\\n  input: &quot;moments/variance/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;moments/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;moments/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n        i: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;moments/Squeeze_1&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;moments/variance&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n        i: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Max/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Max&quot;\\n  op: &quot;Max&quot;\\n  input: &quot;random_normal_2&quot;\\n  input: &quot;Max/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Min/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Min&quot;\\n  op: &quot;Min&quot;\\n  input: &quot;random_normal_2&quot;\\n  input: &quot;Min/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;random_normal_2&quot;\\n  input: &quot;ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;output_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ArgMin/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ArgMin&quot;\\n  op: &quot;ArgMin&quot;\\n  input: &quot;random_normal_2&quot;\\n  input: &quot;ArgMin/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;output_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;norm/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_normal_2&quot;\\n  input: &quot;random_normal_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;norm/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;norm/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;norm/mul&quot;\\n  input: &quot;norm/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;norm/Sqrt&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;norm/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;norm/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;norm/Sqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n        i: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;x_1&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Greater&quot;\\n  op: &quot;Greater&quot;\\n  input: &quot;x_1&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cond/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;Greater&quot;\\n  input: &quot;Greater&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cond/switch_t&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;cond/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cond/switch_f&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;cond/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cond/pred_id&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Greater&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cond/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;cond/sub/Switch:1&quot;\\n  input: &quot;cond/sub/Switch_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cond/sub/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;x_1&quot;\\n  input: &quot;cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@x_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cond/sub/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;y&quot;\\n  input: &quot;cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@y&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cond/sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;cond/sub_1/Switch&quot;\\n  input: &quot;cond/sub_1/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cond/sub_1/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;y&quot;\\n  input: &quot;cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@y&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cond/sub_1/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;x_1&quot;\\n  input: &quot;cond/pred_id&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@x_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cond/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;cond/sub_1&quot;\\n  input: &quot;cond/sub&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;a&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;a&quot;\\n  input: &quot;b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.24123302122509915&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorboard as tb\n",
    "\n",
    "a = tf.placeholder(tf.float32, name='a')\n",
    "b = tf.placeholder(tf.float32, name='b')\n",
    "\n",
    "c = a + b\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([c], feed_dict={a:2, b:3}))\n",
    "\n",
    "tb.show_graph(sess.graph)    # 単純な足し算のグラフの表示 (がしたいが...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. グラフの管理と整理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1. デフォルトグラフによる管理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf`では特に何も指定しなければ、デフォルトグラフと呼ばれるグラフ上に計算グラフが構築されていきます。\n",
    "一度計算グラフ上に配置されたグラフは、そのグラフを使うか使わないかにかかわらず、全てリセットされることなく蓄積されていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'random_normal/shape' type=Const>,\n",
       " <tf.Operation 'random_normal/mean' type=Const>,\n",
       " <tf.Operation 'random_normal/stddev' type=Const>,\n",
       " <tf.Operation 'random_normal/RandomStandardNormal' type=RandomStandardNormal>,\n",
       " <tf.Operation 'random_normal/mul' type=Mul>,\n",
       " <tf.Operation 'random_normal' type=Add>,\n",
       " <tf.Operation 'random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'random_uniform/min' type=Const>,\n",
       " <tf.Operation 'random_uniform/max' type=Const>,\n",
       " <tf.Operation 'random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'random_uniform' type=Add>,\n",
       " <tf.Operation 'Bernoulli/probs' type=Const>,\n",
       " <tf.Operation 'Bernoulli/logits/Log' type=Log>,\n",
       " <tf.Operation 'Bernoulli/logits/mul/x' type=Const>,\n",
       " <tf.Operation 'Bernoulli/logits/mul' type=Mul>,\n",
       " <tf.Operation 'Bernoulli/logits/Log1p' type=Log1p>,\n",
       " <tf.Operation 'Bernoulli/logits/sub' type=Sub>,\n",
       " <tf.Operation 'Bernoulli/sample/sample_shape' type=Const>,\n",
       " <tf.Operation 'Bernoulli/sample/sample_shape_1' type=Const>,\n",
       " <tf.Operation 'Bernoulli/batch_shape_tensor/batch_shape' type=Const>,\n",
       " <tf.Operation 'Bernoulli/sample/concat/values_0' type=Const>,\n",
       " <tf.Operation 'Bernoulli/sample/concat/axis' type=Const>,\n",
       " <tf.Operation 'Bernoulli/sample/concat' type=ConcatV2>,\n",
       " <tf.Operation 'Bernoulli/sample/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'Bernoulli/sample/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'Bernoulli/sample/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'Bernoulli/sample/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'Bernoulli/sample/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'Bernoulli/sample/random_uniform' type=Add>,\n",
       " <tf.Operation 'Bernoulli/sample/Less' type=Less>,\n",
       " <tf.Operation 'Bernoulli/sample/Cast' type=Cast>,\n",
       " <tf.Operation 'Bernoulli/sample/Shape' type=Const>,\n",
       " <tf.Operation 'Bernoulli/sample/strided_slice/stack' type=Const>,\n",
       " <tf.Operation 'Bernoulli/sample/strided_slice/stack_1' type=Const>,\n",
       " <tf.Operation 'Bernoulli/sample/strided_slice/stack_2' type=Const>,\n",
       " <tf.Operation 'Bernoulli/sample/strided_slice' type=StridedSlice>,\n",
       " <tf.Operation 'Bernoulli/sample/concat_1/axis' type=Const>,\n",
       " <tf.Operation 'Bernoulli/sample/concat_1' type=ConcatV2>,\n",
       " <tf.Operation 'Bernoulli/sample/Reshape' type=Reshape>,\n",
       " <tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'Shape' type=Shape>,\n",
       " <tf.Operation 'random_normal_1/mean' type=Const>,\n",
       " <tf.Operation 'random_normal_1/stddev' type=Const>,\n",
       " <tf.Operation 'random_normal_1/RandomStandardNormal' type=RandomStandardNormal>,\n",
       " <tf.Operation 'random_normal_1/mul' type=Mul>,\n",
       " <tf.Operation 'random_normal_1' type=Add>,\n",
       " <tf.Operation 'ones' type=Const>,\n",
       " <tf.Operation 'ExpandDims/dim' type=Const>,\n",
       " <tf.Operation 'ExpandDims' type=ExpandDims>,\n",
       " <tf.Operation 'transpose/perm' type=Const>,\n",
       " <tf.Operation 'transpose' type=Transpose>,\n",
       " <tf.Operation 'Reshape/shape' type=Const>,\n",
       " <tf.Operation 'Reshape' type=Reshape>,\n",
       " <tf.Operation 'Tile/multiples' type=Const>,\n",
       " <tf.Operation 'Tile' type=Tile>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'split/split_dim' type=Const>,\n",
       " <tf.Operation 'split' type=Split>,\n",
       " <tf.Operation 'concat/axis' type=Const>,\n",
       " <tf.Operation 'concat' type=ConcatV2>,\n",
       " <tf.Operation 'ones_1' type=Const>,\n",
       " <tf.Operation 'ones_2' type=Const>,\n",
       " <tf.Operation 'MatMul' type=MatMul>,\n",
       " <tf.Operation 'ones_3' type=Const>,\n",
       " <tf.Operation 'ones_4/shape_as_tensor' type=Const>,\n",
       " <tf.Operation 'ones_4/Const' type=Const>,\n",
       " <tf.Operation 'ones_4' type=Fill>,\n",
       " <tf.Operation 'strided_slice/stack' type=Const>,\n",
       " <tf.Operation 'strided_slice/stack_1' type=Const>,\n",
       " <tf.Operation 'strided_slice/stack_2' type=Const>,\n",
       " <tf.Operation 'strided_slice' type=StridedSlice>,\n",
       " <tf.Operation 'MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'Placeholder' type=Placeholder>,\n",
       " <tf.Operation 'Sigmoid' type=Sigmoid>,\n",
       " <tf.Operation 'Tanh' type=Tanh>,\n",
       " <tf.Operation 'Relu' type=Relu>,\n",
       " <tf.Operation 'Elu' type=Elu>,\n",
       " <tf.Operation 'Softplus' type=Softplus>,\n",
       " <tf.Operation 'Softmax' type=Softmax>,\n",
       " <tf.Operation 'random_normal_2/shape' type=Const>,\n",
       " <tf.Operation 'random_normal_2/mean' type=Const>,\n",
       " <tf.Operation 'random_normal_2/stddev' type=Const>,\n",
       " <tf.Operation 'random_normal_2/RandomStandardNormal' type=RandomStandardNormal>,\n",
       " <tf.Operation 'random_normal_2/mul' type=Mul>,\n",
       " <tf.Operation 'random_normal_2' type=Add>,\n",
       " <tf.Operation 'Sum/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Sum' type=Sum>,\n",
       " <tf.Operation 'moments/mean/reduction_indices' type=Const>,\n",
       " <tf.Operation 'moments/mean' type=Mean>,\n",
       " <tf.Operation 'moments/StopGradient' type=StopGradient>,\n",
       " <tf.Operation 'moments/SquaredDifference' type=SquaredDifference>,\n",
       " <tf.Operation 'moments/variance/reduction_indices' type=Const>,\n",
       " <tf.Operation 'moments/variance' type=Mean>,\n",
       " <tf.Operation 'moments/Squeeze' type=Squeeze>,\n",
       " <tf.Operation 'moments/Squeeze_1' type=Squeeze>,\n",
       " <tf.Operation 'Max/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Max' type=Max>,\n",
       " <tf.Operation 'Min/reduction_indices' type=Const>,\n",
       " <tf.Operation 'Min' type=Min>,\n",
       " <tf.Operation 'ArgMax/dimension' type=Const>,\n",
       " <tf.Operation 'ArgMax' type=ArgMax>,\n",
       " <tf.Operation 'ArgMin/dimension' type=Const>,\n",
       " <tf.Operation 'ArgMin' type=ArgMin>,\n",
       " <tf.Operation 'norm/mul' type=Mul>,\n",
       " <tf.Operation 'norm/Sum/reduction_indices' type=Const>,\n",
       " <tf.Operation 'norm/Sum' type=Sum>,\n",
       " <tf.Operation 'norm/Sqrt' type=Sqrt>,\n",
       " <tf.Operation 'norm/Squeeze' type=Squeeze>,\n",
       " <tf.Operation 'x_1' type=Placeholder>,\n",
       " <tf.Operation 'y' type=Placeholder>,\n",
       " <tf.Operation 'Greater' type=Greater>,\n",
       " <tf.Operation 'cond/Switch' type=Switch>,\n",
       " <tf.Operation 'cond/switch_t' type=Identity>,\n",
       " <tf.Operation 'cond/switch_f' type=Identity>,\n",
       " <tf.Operation 'cond/pred_id' type=Identity>,\n",
       " <tf.Operation 'cond/sub' type=Sub>,\n",
       " <tf.Operation 'cond/sub/Switch' type=Switch>,\n",
       " <tf.Operation 'cond/sub/Switch_1' type=Switch>,\n",
       " <tf.Operation 'cond/sub_1' type=Sub>,\n",
       " <tf.Operation 'cond/sub_1/Switch' type=Switch>,\n",
       " <tf.Operation 'cond/sub_1/Switch_1' type=Switch>,\n",
       " <tf.Operation 'cond/Merge' type=Merge>,\n",
       " <tf.Operation 'a' type=Placeholder>,\n",
       " <tf.Operation 'b' type=Placeholder>,\n",
       " <tf.Operation 'add' type=Add>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 今までの実行によりデフォルトグラフ上に溜まったオペレーション\n",
    "tf.get_default_graph().get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'a:0' shape=() dtype=int32_ref>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 今までの実行によりデフォルトグラフ上に溜まったVariables\n",
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そのため、このままでは使わないゴミリソースが蓄積され続けてしまいます。\n",
    "\n",
    "`tf.reset_default_graph`を毎回新しくグラフを構築する際に呼び出すことにより、これを避けることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.03348572713329834&quot;).pbtxt = 'node {\\n  name: &quot;x&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;t&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\005\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;random_uniform/max&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_uniform/RandomUniform&quot;\\n  input: &quot;random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_uniform/mul&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;W&quot;\\n  input: &quot;random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;W/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;zeros/shape_as_tensor&quot;\\n  input: &quot;zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;b&quot;\\n  input: &quot;zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;x&quot;\\n  input: &quot;W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MatMul&quot;\\n  input: &quot;b/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;y&quot;\\n  input: &quot;t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;pow/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;pow&quot;\\n  op: &quot;Pow&quot;\\n  input: &quot;sub&quot;\\n  input: &quot;pow/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Rank&quot;\\n  op: &quot;Rank&quot;\\n  input: &quot;pow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;range/start&quot;\\n  input: &quot;Rank&quot;\\n  input: &quot;range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;pow&quot;\\n  input: &quot;range&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.03348572713329834&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# グラフのリセット\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# プレースホルダーと変数の宣言\n",
    "x = tf.placeholder(tf.float32, name='x')\n",
    "t = tf.placeholder(tf.float32, name='t')\n",
    "W = tf.Variable(tf.random_uniform((5, 3), -1.0, 1.0), name='W')\n",
    "b = tf.Variable(tf.zeros((3)), name='b')\n",
    "\n",
    "# グラフの構築\n",
    "y = tf.add(tf.matmul(x, W), b, name='y')\n",
    "\n",
    "# 誤差関数の定義\n",
    "cost = tf.reduce_mean((y - t)**2, name='cost')\n",
    "\n",
    "tb.show_graph(tf.Session().graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2. namespaceによる管理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.reset_default_graph`を呼び出すことにより、毎回クリーンな状態でグラフを構築していくことができます。\n",
    "ただグラフが大規模になってくると、以前変数が多くなりグラフtensorboard上などでノードが見づらくなってしまいます。\n",
    "\n",
    "tf.name_scope関数を使ってノードをグループに分けることにより、この問題を解消することができます。\n",
    "\n",
    "まとめられたノードは、カーソルをかざすと出てくる右上のプラスマークをクリックすることで展開することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.013420609739402511&quot;).pbtxt = 'node {\\n  name: &quot;x&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;t&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\005\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;variables/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;variables/random_uniform/max&quot;\\n  input: &quot;variables/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;variables/random_uniform/RandomUniform&quot;\\n  input: &quot;variables/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;variables/random_uniform/mul&quot;\\n  input: &quot;variables/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/W&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/W/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;variables/W&quot;\\n  input: &quot;variables/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@variables/W&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/W/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;variables/W&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@variables/W&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;variables/zeros/shape_as_tensor&quot;\\n  input: &quot;variables/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/b&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/b/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;variables/b&quot;\\n  input: &quot;variables/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@variables/b&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;variables/b/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;variables/b&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@variables/b&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;model/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;x&quot;\\n  input: &quot;variables/W/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;model/y&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;model/MatMul&quot;\\n  input: &quot;variables/b/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;model/y&quot;\\n  input: &quot;t&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;training/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Rank&quot;\\n  op: &quot;Rank&quot;\\n  input: &quot;training/Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;training/range/start&quot;\\n  input: &quot;training/Rank&quot;\\n  input: &quot;training/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/cost&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;training/Square&quot;\\n  input: &quot;training/range&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.013420609739402511&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, name='x')\n",
    "t = tf.placeholder(tf.float32, name='t')\n",
    "\n",
    "with tf.name_scope('variables'):\n",
    "    W = tf.Variable(tf.random_uniform((5, 3), -1.0, 1.0), name='W')\n",
    "    b = tf.Variable(tf.zeros((3)), name='b')\n",
    "\n",
    "with tf.name_scope('model'):\n",
    "    y = tf.add(tf.matmul(x, W), b, name='y')\n",
    "\n",
    "with tf.name_scope('training'):\n",
    "    cost = tf.reduce_mean(tf.square(y - t), name='cost')\n",
    "\n",
    "tb.show_graph(tf.Session().graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3. グラフの切り分けによる管理\n",
    "\n",
    "デフォルトグラフではなく、明示的にグラフオブジェクトを作成し、その上にグラフを構築していくことでグラフ環境を他と分けることも可能です。\n",
    "\n",
    "これは複数のグラフを構築していきたいときなどに便利です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # グラフのリセット\n",
    "\n",
    "g0 = tf.get_default_graph() # デフォルトグラフオブジェクトを取得することも可能\n",
    "\n",
    "g1 = tf.Graph() # グラフオブジェクトの作成1\n",
    "\n",
    "a = tf.constant(2, name='a0') # これはdefault graphへの配置になるので注意\n",
    "b = a**a\n",
    "\n",
    "with g1.as_default(): # デフォルトに設定した上で, グラフを構築・操作\n",
    "    a = tf.constant(2, name='a')\n",
    "    b = a**a\n",
    "\n",
    "g2 = tf.Graph() # グラフオブジェクトの作成2\n",
    "\n",
    "with g2.as_default(): # デフォルトに設定し, グラフを構築\n",
    "    a = tf.constant(4, name='a')\n",
    "    x = tf.constant(3, name='x')\n",
    "    y = a**x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.6484727848231905&quot;).pbtxt = 'node {\\n  name: &quot;a0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;pow&quot;\\n  op: &quot;Pow&quot;\\n  input: &quot;a0&quot;\\n  input: &quot;a0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.6484727848231905&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tb.show_graph(g0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.8693687459490342&quot;).pbtxt = 'node {\\n  name: &quot;a&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;pow&quot;\\n  op: &quot;Pow&quot;\\n  input: &quot;a&quot;\\n  input: &quot;a&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.8693687459490342&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session(graph=g1) as sess:\n",
    "    print(sess.run(b))\n",
    "tb.show_graph(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.6090357034477198&quot;).pbtxt = 'node {\\n  name: &quot;a&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;pow&quot;\\n  op: &quot;Pow&quot;\\n  input: &quot;a&quot;\\n  input: &quot;x&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.6090357034477198&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session(graph=g2) as sess:\n",
    "    print(sess.run(y))\n",
    "tb.show_graph(g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. モデルの保存・読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.train.Saver`を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ (OR)\n",
    "x_data = np.array([[0, 1], [1, 0], [0, 0], [1, 1]])\n",
    "t_data = np.array([[1], [1], [0], [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 100, Train Cost, 0.158\n",
      "EPOCH: 200, Train Cost, 0.090\n",
      "EPOCH: 300, Train Cost, 0.062\n",
      "EPOCH: 400, Train Cost, 0.047\n",
      "EPOCH: 500, Train Cost, 0.038\n",
      "EPOCH: 600, Train Cost, 0.032\n",
      "EPOCH: 700, Train Cost, 0.027\n",
      "EPOCH: 800, Train Cost, 0.024\n",
      "EPOCH: 900, Train Cost, 0.021\n",
      "EPOCH: 1000, Train Cost, 0.019\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9835565 ],\n",
       "       [0.9835535 ],\n",
       "       [0.04125246],\n",
       "       [0.99998796]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=(None, 2), name='x')\n",
    "t = tf.placeholder(dtype=tf.float32, shape=(None, 1), name='t')\n",
    "\n",
    "W = tf.Variable(tf.random_uniform(shape=(2, 1), minval=-0.08, maxval=0.08, dtype=tf.float32), name='W')\n",
    "b = tf.Variable(tf.zeros(shape=(1), dtype=tf.float32), name='b')\n",
    "\n",
    "y = tf.nn.sigmoid(tf.matmul(x, W) + b)\n",
    "\n",
    "cost = - tf.reduce_mean(tf.reduce_sum(t * tf.log(y) + (1 - t) * tf.log(1 - y), axis=1))\n",
    "\n",
    "gW, gb = tf.gradients(cost, [W, b]) # 勾配の計算\n",
    "updates = [\n",
    "    W.assign_sub(0.5 * gW), # 勾配降下法\n",
    "    b.assign_sub(0.5 * gb)\n",
    "]\n",
    "train = tf.group(*updates)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) # 重み (Variable) の初期化\n",
    "for epoch in range(1000):\n",
    "    cost_, _ = sess.run([cost, train], feed_dict={x: x_data, t: t_data})\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print('EPOCH: {}, Train Cost, {:.3f}'.format(epoch + 1, cost_))\n",
    "\n",
    "print()\n",
    "y_pred = sess.run(y, feed_dict={x: x_data})\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/model.ckpt'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, '/tmp/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/takuma.s/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=(None, 2), name='x')\n",
    "t = tf.placeholder(dtype=tf.float32, shape=(None, 1), name='t')\n",
    "\n",
    "W = tf.Variable(tf.random_uniform(shape=(2, 1), minval=-0.08, maxval=0.08, dtype=tf.float32), name='W')\n",
    "b = tf.Variable(tf.zeros(shape=(1), dtype=tf.float32), name='b')\n",
    "\n",
    "y = tf.nn.sigmoid(tf.matmul(x, W) + b)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "saver.restore(sess, '/tmp/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9835565 ],\n",
       "       [0.9835535 ],\n",
       "       [0.04125246],\n",
       "       [0.99998796]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = sess.run(y, feed_dict={x: x_data})\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. メモリの管理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowは、デフォルトでは最初のSessionを開始した時点でシステム上のすべてのGPUのすべてのメモリを専有してしまいます。これは共用のサーバーなどでは特に避けなければいけません。(iLect上では特に気にしなくて大丈夫です。）\n",
    "\n",
    "ここではいくつかの方法で使用するメモリを制御するいくつかの方法を紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1. 使用するGPU(数)を制限する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 方法 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf`から見えるGPUを制限します."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 方法 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指定したgpu上にグラフを展開していきます."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    x = tf.zeros(4)\n",
    "    # グラフの構築\n",
    "    # ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 GPU上のメモリ使用量を制限する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 方法 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf`ではGPUメモリ上に最初にオブジェクトが展開される際、そのオブジェクトのサイズにかかわらずGPU上のすべてのメモリを専有してしまいます。\n",
    "\n",
    "これをオブジェクトのサイズに応じて段階的にメモリが使用されるように変更します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "x = tf.random_normal((100, 100))\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    pass\n",
    "\n",
    "# ! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 方法 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf`が一定割合のメモリのみ使用できるように設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5 # 50%のメモリのみ使用\n",
    "\n",
    "x = tf.random_normal((100, 100))\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    pass\n",
    "\n",
    "# ! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "詳細は https://www.tensorflow.org/guide/using_gpu を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. `tf.data` APIの利用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(以下の説明は`tf.data`の公式ドキュメント https://www.tensorflow.org/guide/datasets を元にしています)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "いままでは`feed_dict`に毎回NumPyオブジェクト等を流し込むことにより学習ループを回していました。\n",
    "\n",
    "もう一つの方法として事前にデータを`tf`のオブジェクト`tf.data.Dataset`に変換し、毎回のNumPyオブジェクトからの変換を省くやり方があります。\n",
    "\n",
    "入力データが大規模になったり複数のGPUを使う際にはこれにより学習の高速化が期待できます。(参考: Tensorflow Performance Guide: https://www.tensorflow.org/performance/performance_guide)\n",
    "\n",
    "この場合、グラフの構築の際に\n",
    "\n",
    "1. NumPyオブジェクトから`Dataset`オブジェクトへの変換\n",
    "2. Iteratorの設定\n",
    "\n",
    "を行う必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.1. `tf.data.Dataset`\n",
    "\n",
    "まず通常のメモリ上のデータ (ndarray等) から`tf.data.Dataset`に変換します。これには`tf.data.Dataset.from_tensor_slices`などを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ (OR)\n",
    "x_data = np.array([[0, 1], [1, 0], [0, 0], [1, 1]]).astype(np.float32)\n",
    "t_data = np.array([[1], [1], [0], [1]]).astype(np.float32)\n",
    "\n",
    "x_train, t_train = x_data, t_data\n",
    "x_valid, t_valid = x_data, t_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# ndarrayからDatasetへ変換\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "\n",
    "# 複数のオブジェクトをまとめて変換する場合はタプルで渡す\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, t_train))\n",
    "\n",
    "# Dataset同士をまとめる場合はDataset.zipを利用\n",
    "dataset_x = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "dataset_t = tf.data.Dataset.from_tensor_slices(t_train)\n",
    "\n",
    "dataset = tf.data.Dataset.zip((dataset_x, dataset_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また`tf.placeholder`を利用して空の`Dataset`を作成することも可能です。ただしこの場合はデータを別の方法で流し込む必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32'>\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "data = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "\n",
    "# 型情報のみが保存される\n",
    "print(dataset.output_types)\n",
    "print(dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、`shuffle`、`batch`、`repeat`、`map`等を利用して前処理部分を書くことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# ndarrayからDatasetへ変換\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "\n",
    "# 適当な前処理\n",
    "dataset = dataset.map(lambda x: x * tf.random_normal([], dtype=tf.float32))\n",
    "\n",
    "# Dataset内のシャッフル (引数でシャッフル時のバッファ数を指定)\n",
    "dataset = dataset.shuffle(len(x_data))\n",
    "\n",
    "# データセットを繰り返す回数 (エポック数) を指定\n",
    "dataset = dataset.repeat(3)\n",
    "\n",
    "# バッチサイズを指定. 次元が最初に1つ追加される\n",
    "print(dataset.output_shapes)\n",
    "dataset = dataset.batch(4)\n",
    "print(dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.2. `tf.data.Iterator`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次にIteratorにより、`Dataset`内の要素をどのように走査するかを決めていきます。\n",
    "\n",
    "現在4つのIterator (One-shot, Initializable, Reinitializable, Feedable) が用意されています。後ろに行くほど柔軟性が高いものになっています。またどのIteratorにおいても走査終了時にはエラー ('tf.errors.OutOfRangeError') が投げられます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One-shot iterator\n",
    "Datasetを一回だけ走査するiteratorです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x_data).shuffle(len(x_data))\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "x = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            sess.run(x)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('End of dataset')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initializable iterator\n",
    "one-shot iteratorと違い再利用可能なiteratorです。`iterator.initializer`によって初期化してから使用します。\n",
    "\n",
    "主に`tf.placeholder`などから作成された空の`Dataset`に対して適用します。\n",
    "\n",
    "訓練データと検証データを`tf.placeholder`で入れ替えたい場合などに便利です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "data = tf.placeholder(tf.float32, shape=(4, 2))\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "x = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Train\n",
    "    sess.run(iterator.initializer, feed_dict={data: x_train})\n",
    "    while True:\n",
    "        try:\n",
    "            sess.run(x)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('End of train dataset')\n",
    "            break\n",
    "    \n",
    "    # Valid\n",
    "    sess.run(iterator.initializer, feed_dict={data: x_valid})\n",
    "    while True:\n",
    "        try:\n",
    "            sess.run(x)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('End of valid dataset')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reinitializable iterator\n",
    "型情報のみから作成されるIteratorです。\n",
    "\n",
    "異なる`Dataset`に渡って使用することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "dataset_train = dataset_train.map(lambda x: x + tf.random_normal([]))\n",
    "\n",
    "dataset_valid = tf.data.Dataset.from_tensor_slices(x_valid)\n",
    "\n",
    "# Iteratorの型を指定\n",
    "iterator = tf.data.Iterator.from_structure(\n",
    "    output_types=dataset_train.output_types,\n",
    "    output_shapes=dataset_train.output_shapes\n",
    ")\n",
    "\n",
    "x = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Train\n",
    "    sess.run(iterator.make_initializer(dataset_train)) # 訓練データでiteratorを初期化\n",
    "    while True:\n",
    "        try:\n",
    "            sess.run(x)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('End of train dataset')\n",
    "            break\n",
    "    \n",
    "    # Valid\n",
    "    sess.run(iterator.make_initializer(dataset_valid)) # 検証データでiteratorを初期化\n",
    "    while True:\n",
    "        try:\n",
    "            sess.run(x)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('End of valid dataset')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feedable iterator\n",
    "どのIteratorを操作するかを柔軟に決めることのできるIteratorです。複数のIteratorの中からどれをiterateするかをfeed_dictにより指定して実行します。\n",
    "\n",
    "Iteratorを初期化することなく複数のIterator間を行き来できるので、たとえば訓練データの一定iterationごとに検証データを回したいなどの場面で有用です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((x_train, t_train))\n",
    "dataset_train = dataset_train.repeat()\n",
    "\n",
    "dataset_valid = tf.data.Dataset.from_tensor_slices((x_valid, t_valid))\n",
    "\n",
    "handle = tf.placeholder(tf.string)\n",
    "iterator = tf.data.Iterator.from_string_handle(\n",
    "    string_handle=handle,\n",
    "    output_types=dataset_train.output_types,\n",
    "    output_shapes=dataset_train.output_shapes\n",
    ")\n",
    "\n",
    "iterator_train = dataset_train.make_one_shot_iterator()\n",
    "iterator_valid = dataset_valid.make_initializable_iterator()\n",
    "\n",
    "x, t = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    handle_train = sess.run(iterator_train.string_handle())\n",
    "    handle_valid = sess.run(iterator_valid.string_handle())\n",
    "        \n",
    "    # Train\n",
    "    for i in range(500):\n",
    "        sess.run(x, feed_dict={handle: handle_train})\n",
    "\n",
    "        # 100回繰り返すごとにvalidation\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Iteration: {}'.format(i + 1))\n",
    "            # Valid\n",
    "            sess.run(iterator_valid.initializer)\n",
    "            while True:\n",
    "                try:\n",
    "                    sess.run(x, feed_dict={handle: handle_valid})\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    print('End of validation dataset')\n",
    "                    break\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TensorFlowによるニューラルネットワークの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.gradients`を使うことで様々なOptimizerを実装することができます。\n",
    "\n",
    "(tfにはbuilt-inで様々なOptimizerが実装されていますが、今回のchap05ではそのような高レベルAPIは使用せず、代わりに各自で実装していただきます。宿題においても同様です。）\n",
    "\n",
    "いくつかのOptimizerを例として以下に示します。また、個々の学習パラメータ (${\\bf W}$や${\\bf b}$の各要素)を以下では一般化して$\\theta\\in\\mathbb{R}$で表しています。\n",
    "また、ステップ$t$における誤差関数$E$に対する学習パラメータ$\\theta$の微分を$g_{t}$で表します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD\n",
    "\n",
    "\\begin{align*}\n",
    "    \\theta_{t+1} = \\theta_{t} - \\eta \\cdot g_{t}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(cost, params, eta=0.01):\n",
    "    grads = tf.gradients(cost, params)\n",
    "    updates = []\n",
    "    for param, grad in zip(params, grads):\n",
    "        updates.append(param.assign_sub(eta * grad))\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Momentum\n",
    "\n",
    "\\begin{align*}\n",
    "    v_{t} = \\gamma v_{t-1} + \\eta \\cdot g_{t} \\\\\n",
    "    \\theta_{t+1} = \\theta_{t} - v_{t}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum(cost, params, eta=0.01, gamma=0.9):\n",
    "    grads = tf.gradients(cost, params)\n",
    "    updates = []\n",
    "    for param, grad in zip(params, grads):\n",
    "        v = tf.Variable(tf.zeros_like(param, dtype=tf.float32), name='v')\n",
    "        updates.append(v.assign(gamma * v + eta * grad))\n",
    "        with tf.control_dependencies(updates):\n",
    "            updates.append(param.assign_sub(v))\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adagrad\n",
    "\n",
    "\\begin{align*}\n",
    "    G_{t} = G_{t-1} + g^{2}_t \\\\\n",
    "    \\theta_{t+1} = \\theta_{t} - \\frac{\\eta}{\\sqrt{G_{t} + \\epsilon}} \\cdot g_{t}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adagrad(cost, params, eta=0.01, eps=1e-7):\n",
    "    grads = tf.gradients(cost, params)\n",
    "    updates = []\n",
    "    for param, grad in zip(params, grads):\n",
    "        G = tf.Variable(tf.zeros_like(param, dtype=tf.float32), name=\"G\")\n",
    "        updates.append(G.assign_add(grad ** 2))\n",
    "        with tf.control_dependencies(updates):\n",
    "            updates.append(param.assign_sub(eta * grad / tf.sqrt(G + eps)))\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSProp\n",
    "\n",
    "\\begin{align*}\n",
    "    \\tilde{G}_{t} = \\rho \\cdot \\tilde{G}_{t-1} + (1 - \\rho) \\cdot g^{2}_{t} \\\\\n",
    "    \\theta_{t+1} = \\theta_{t} - \\frac{\\eta}{\\sqrt{\\tilde{G}_{t} + \\epsilon}} \\cdot g_{t}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsprop(cost, params, eta=0.001, rho=0.9, eps=1e-7):\n",
    "    grads = tf.gradients(cost, params)\n",
    "    updates = []\n",
    "    for param, grad in zip(params, grads):\n",
    "        G = tf.Variable(tf.zeros_like(param, dtype=tf.float32), name='G')\n",
    "        updates.append(G.assign(rho * G + (1 - rho) * grad**2))\n",
    "        with tf.control_dependencies(updates):\n",
    "            updates.append(param.assign_sub(eta / tf.sqrt(G + eps) * grad))\n",
    "\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adadelta、Adam等も同じ要領で実装できるので、余裕のある人は実装してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropoutを適用するには`tf.nn.dropout`を使います。\n",
    "\n",
    "引数の`keep_prob`でユニットをキープする確率を設定します。また、関数の出力は$\\frac{1}{\\text{keep_prob}}$倍されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-eeadf8df8c3d>:6: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "[0. 2. 2. 2. 2. 2. 2. 0. 2. 0.]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(34)\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "x_dropped = tf.nn.dropout(x, keep_prob=0.5)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(x_dropped, feed_dict={x: np.ones(10)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. 正則化 (重み減衰)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1正則化\n",
    "\\begin{align*}\n",
    "    \\tilde{E} = E + \\lambda \\sum_{\\theta} |\\theta|\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_l1_reg(params):\n",
    "    l1_reg = 0\n",
    "    for param in params:\n",
    "        l1_reg += tf.reduce_sum(tf.abs(param))\n",
    "    return l1_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2正則化\n",
    "\\begin{align*}\n",
    "    \\tilde{E} = E + \\lambda \\sum_{\\theta} \\theta^2\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_l2_reg(params):\n",
    "    l2_reg = 0\n",
    "    for param in params:\n",
    "        l2_reg += tf.reduce_sum(tf.square(param))\n",
    "    return l2_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. MLPの実装 (`tf.data.Dataset`を使用しない版)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowを使ってMLPを実装してみましょう。\n",
    "\n",
    "データセットにはMNISTを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/takuma.s/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/takuma.s/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 8] nodename nor servname provided, or not known>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0;32m-> 1317\u001b[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[1;32m   1318\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    927\u001b[0m         self.sock = self._create_connection(\n\u001b[0;32m--> 928\u001b[0;31m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[1;32m    929\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-b2418a9da534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_mldata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_mldata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MNIST original'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_home\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"../../\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx_mnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mt_mnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/datasets/mldata.py\u001b[0m in \u001b[0;36mfetch_mldata\u001b[0;34m(dataname, target_name, data_name, transpose_data, data_home)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0murlname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLDATA_BASE_URL\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mquote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mmldata_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 543\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 8] nodename nor servname provided, or not known>"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original', data_home=\"../../\")\n",
    "\n",
    "x_mnist = mnist.data.astype('float32') / 255.\n",
    "t_mnist = np.eye(10)[mnist.target.astype('int32')]\n",
    "\n",
    "x_train_mnist, x_test_mnist, t_train_mnist, t_test_mnist = train_test_split(x_mnist, t_mnist, test_size=10000)\n",
    "x_train_mnist, x_valid_mnist, t_train_mnist, t_valid_mnist = train_test_split(x_train_mnist, t_train_mnist, test_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fashion mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train = np.load('../data/x_train.npy')\n",
    "t_train = np.load('../data/y_train.npy')\n",
    "x_train = x_train.reshape(-1, 784).astype('float32') / 255\n",
    "t_train = np.eye(10)[t_train.astype('int32')]\n",
    "x_train, x_valid, t_train, t_valid = train_test_split(x_train, t_train, test_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全結合層とDropout層からなるMLPを実装します。\n",
    "\n",
    "順伝播の式を示します。\n",
    "$$\n",
    "\\begin{align*}\n",
    "    {\\bf u}^{(1)} &= {\\bf W}^{(1)\\mathrm{T}} {\\bf x} + {\\bf b}^{(1)} \\\\\n",
    "    {\\bf h}^{(1)} &= \\mathrm{ReLU}({\\bf u}^{(1)}) \\\\\n",
    "    {\\bf \\tilde{h}}^{(1)} &= \\mathrm{Dropout}({\\bf h}^{(1)}) \\\\\n",
    "    {\\bf u}^{(2)} &= {\\bf W}^{(2)\\mathrm{T}} {\\bf \\tilde{h}}^{(1)} + {\\bf b}^{(2)} \\\\\n",
    "    {\\bf h}^{(2)} &= \\mathrm{ReLU}({\\bf u}^{(2)}) \\\\\n",
    "    {\\bf \\tilde{h}}^{(2)} &= \\mathrm{Dropout}({\\bf h}^{(2)}) \\\\\n",
    "    {\\bf u}^{(3)} &= {\\bf W}^{(3)\\mathrm{T}} {\\bf \\tilde{h}}^{(2)} + {\\bf b}^{(3)} \\\\\n",
    "    {\\bf y} &= \\mathrm{softmax} ({\\bf u}^{(3)})\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全結合層とDropout層を定義します。\n",
    "\n",
    "Dropout層では、訓練時と検証時のDropoutを適用の有無を`tf.cond`により制御します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    def __init__(self, in_dim, out_dim, function=lambda x: x):\n",
    "        self.W = tf.Variable(tf.random_uniform(shape=(in_dim, out_dim), minval=-0.08, maxval=0.08), name='W')\n",
    "        self.b = tf.Variable(tf.zeros(out_dim), name='b')\n",
    "        self.function = function\n",
    "        \n",
    "        self.params = [self.W, self.b]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.function(tf.matmul(x, self.W) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, dropout_keep_prob=1.0):\n",
    "        self.dropout_keep_prob = dropout_keep_prob\n",
    "        self.params = []\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # 訓練時のみdropoutを適用\n",
    "        return tf.cond(\n",
    "            pred=is_training,\n",
    "            true_fn=lambda: tf.nn.dropout(x, keep_prob=self.dropout_keep_prob),\n",
    "            false_fn=lambda: x\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "誤差関数は通常の他クラス交差エントロピーにL2正則化の項を追加したものを使用します。\n",
    "$$\n",
    "    E = -\\frac{1}{N}\\sum^N_{i=1} \\sum^K_{k=1} {\\bf t}_{i, k} \\log {\\bf y}_{i, k} + \\lambda\\sum_{\\theta}\\theta^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.log(0)によるnanを防ぐ\n",
    "def tf_log(x):\n",
    "    return tf.log(tf.clip_by_value(x, 1e-10, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.01 # 学習率\n",
    "dropout_keep_prob = 0.5 # Dropout率\n",
    "lmd = 0.001 # L2正則化項の係数\n",
    "batch_size = 32 # バッチサイズ\n",
    "n_epochs = 10 # epoch数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # グラフのリセット\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 784)) # 入力データ\n",
    "t = tf.placeholder(tf.float32, (None, 10)) # 教師データ\n",
    "is_training = tf.placeholder(tf.bool) # 訓練時orテスト時\n",
    "\n",
    "layers = [\n",
    "    Dense(784, 200, tf.nn.relu),\n",
    "    Dropout(dropout_keep_prob),\n",
    "    Dense(200, 200, tf.nn.relu),\n",
    "    Dropout(dropout_keep_prob),\n",
    "    Dense(200, 10, tf.nn.softmax)\n",
    "]\n",
    "\n",
    "def get_params(layers):\n",
    "    params_all = []\n",
    "    for layer in layers:\n",
    "        params = layer.params\n",
    "        params_all.extend(params)\n",
    "    return params_all\n",
    "\n",
    "def f_props(layers, h):\n",
    "    for layer in layers:\n",
    "        h = layer(h)\n",
    "    return h\n",
    "\n",
    "y = f_props(layers, x)\n",
    "params_all = get_params(layers)\n",
    "l2_reg = compute_l2_reg(params_all)\n",
    "\n",
    "cost = - tf.reduce_mean(tf.reduce_sum(t * tf_log(y), axis=1)) + lmd * l2_reg\n",
    "\n",
    "updates = sgd(cost, params_all, eta)\n",
    "train = tf.group(*updates)\n",
    "\n",
    "n_batches = math.ceil(len(x_train) / batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1, Valid Cost: 1.148, Valid Accuracy: 0.713\n",
      "EPOCH: 2, Valid Cost: 1.004, Valid Accuracy: 0.781\n",
      "EPOCH: 3, Valid Cost: 0.916, Valid Accuracy: 0.813\n",
      "EPOCH: 4, Valid Cost: 0.861, Valid Accuracy: 0.829\n",
      "EPOCH: 5, Valid Cost: 0.813, Valid Accuracy: 0.844\n",
      "EPOCH: 6, Valid Cost: 0.784, Valid Accuracy: 0.840\n",
      "EPOCH: 7, Valid Cost: 0.753, Valid Accuracy: 0.843\n",
      "EPOCH: 8, Valid Cost: 0.728, Valid Accuracy: 0.857\n",
      "EPOCH: 9, Valid Cost: 0.699, Valid Accuracy: 0.856\n",
      "EPOCH: 10, Valid Cost: 0.678, Valid Accuracy: 0.860\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(n_epochs):\n",
    "        x_train, t_train = shuffle(x_train, t_train)\n",
    "        for i in range(n_batches):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            sess.run(train, feed_dict={x: x_train[start:end], t: t_train[start:end], is_training: True})\n",
    "        y_pred, cost_valid_ = sess.run([y, cost], feed_dict={x: x_valid, t: t_valid, is_training: False})\n",
    "        print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
    "            epoch + 1,\n",
    "            cost_valid_,\n",
    "            accuracy_score(t_valid.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. `tf.data.Dataset`を用いた実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考として`tf.data.Dataset`を使用した実装を以下に示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((x_train, t_train))\n",
    "dataset_train = dataset_train.repeat()\n",
    "dataset_train = dataset_train.batch(batch_size)\n",
    "flag_true = tf.data.Dataset.from_tensor_slices(tf.ones(len(x_train), dtype=tf.bool))\n",
    "flag_true = flag_true.repeat()\n",
    "dataset_train = tf.data.Dataset.zip((dataset_train, flag_true))\n",
    "\n",
    "dataset_valid = tf.data.Dataset.from_tensor_slices((x_valid, t_valid))\n",
    "dataset_valid = dataset_valid.batch(batch_size)\n",
    "flag_false = tf.data.Dataset.from_tensor_slices(tf.zeros(len(x_valid), dtype=tf.bool))\n",
    "dataset_valid = tf.data.Dataset.zip((dataset_valid, flag_false))\n",
    "\n",
    "handle = tf.placeholder(tf.string)\n",
    "iterator = tf.data.Iterator.from_string_handle(\n",
    "    string_handle=handle,\n",
    "    output_types=dataset_train.output_types,\n",
    "    output_shapes=dataset_train.output_shapes\n",
    ")\n",
    "\n",
    "iterator_train = dataset_train.make_one_shot_iterator()\n",
    "iterator_valid = dataset_valid.make_initializable_iterator()\n",
    "\n",
    "(x, t), is_training = iterator.get_next()\n",
    "\n",
    "layers = [\n",
    "    Dense(784, 200, tf.nn.relu),\n",
    "    Dropout(dropout_keep_prob),\n",
    "    Dense(200, 200, tf.nn.relu),\n",
    "    Dropout(dropout_keep_prob),\n",
    "    Dense(200, 10, tf.nn.softmax)\n",
    "]\n",
    "\n",
    "def get_params(layers):\n",
    "    params_all = []\n",
    "    for layer in layers:\n",
    "        params = layer.params\n",
    "        params_all += params\n",
    "    return params_all\n",
    "\n",
    "def f_props(layers, h):\n",
    "    for layer in layers:\n",
    "        h = layer(h)\n",
    "    return h\n",
    "\n",
    "y = f_props(layers, x)\n",
    "params_all = get_params(layers)\n",
    "l2_reg = compute_l2_reg(params_all)\n",
    "\n",
    "cost = - tf.reduce_mean(tf.reduce_sum(t * tf_log(y), axis=1)) + lmd * l2_reg\n",
    "\n",
    "updates = sgd(cost, params_all, eta)\n",
    "train = tf.group(*updates)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    handle_train = sess.run(iterator_train.string_handle())\n",
    "    handle_valid = sess.run(iterator_valid.string_handle())\n",
    "    \n",
    "    for i in range(10000):\n",
    "        # Train\n",
    "        sess.run(train, feed_dict={handle: handle_train})\n",
    "        \n",
    "        # Valid\n",
    "        if (i + 1) % 2000 == 0:\n",
    "            sess.run(iterator_valid.initializer)\n",
    "            costs_valid = []\n",
    "            y_preds = []\n",
    "            while True:\n",
    "                try:\n",
    "                    cost_, y_pred = sess.run([cost, y], feed_dict={handle: handle_valid})\n",
    "                    costs_valid.append(cost_)\n",
    "                    y_preds.extend(y_pred.argmax(axis=1))\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "            print('Iteration: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
    "                i + 1,\n",
    "                np.mean(costs_valid),\n",
    "                accuracy_score(t_valid.argmax(axis=1), y_preds)\n",
    "            ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
