{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第10回講義 演習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "rng = np.random.RandomState(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目次"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "課題. Variational auto-encoder (VAE)によるMNISTの画像生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Variational auto-encoder (VAE)の実装\n",
    "  - 1.1. MNISTデータセットの読み込み\n",
    "  - 1.2. VAEの実装\n",
    "  - 1.3. パラメータの更新設定\n",
    "  - 1.4. 学習\n",
    "2. 再構成画像の可視化\n",
    "  - 2.1. Encoder\n",
    "  - 2.2. Decoder\n",
    "  - 2.3. Original image\n",
    "  - 2.4. Reconstruction image\n",
    "3. 潜在変数からランダムサンプリング\n",
    "3. 潜在空間の多様体の可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課題. Variational auto-encoder (VAE)によるMNISTの画像生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Variational auto-encoder (VAE) の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. MNISTデータセットの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()\n",
    "\n",
    "x_train = (x_train.reshape(-1, 784) / 255).astype(np.float32)\n",
    "x_valid = (x_valid.reshape(-1, 784) / 255).astype(np.float32)\n",
    "\n",
    "y_train = np.eye(10)[y_train].astype(np.float32)\n",
    "y_valid = np.eye(10)[y_valid].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. VAEの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./../figures/figure1.png\" align=\"left\" width=\"35%\" height=\"35%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAEのエンコーダとデコーダは、それぞれ次のように表されます。\n",
    "- エンコーダ（ガウス分布）：$q_{\\phi}({\\bf z}|{\\bf x}) = {\\mathcal N}({\\bf z}; \\mu,\\sigma^2{\\bf I})$, ただし$\\mu=g^{\\mu}_{\\phi}({\\bf x}), \\sigma=g^{\\sigma}_{\\phi}({\\bf x})$.\n",
    "- デコーダ（ベルヌーイ分布）：$p_{\\theta}({\\bf x}|{\\bf z}) = Ber({\\bf x}; \\lambda)$, ただし$\\lambda=f_{\\theta}({\\bf z})$.\n",
    "\n",
    "\n",
    "また、VAEの下界（目的関数）は次のとおりです。\n",
    "\n",
    "${\\mathcal L}({\\bf x};{\\bf \\theta},{\\bf \\phi}) = E_{q_{\\phi}({\\bf z}|{\\bf x})}[\\log p_\\theta({\\bf x}|{\\bf z})] -D_{KL}[q_{\\phi}({\\bf z}|{\\bf x})||p_{\\theta}({\\bf z})]$\n",
    "\n",
    "第1項が（負の）再構成誤差、第2項が正則化項に対応しています。\n",
    "\n",
    "- 第1項は、次のように計算できます。\n",
    "\n",
    "  $E_{q_{\\phi}({\\bf z}|{\\bf x})}[\\log p_\\theta({\\bf x}|{\\bf z})]=\\frac{1}{L}\\sum_{l=1}^L\\log p_\\theta({\\bf x}|{\\bf z}^{(l)})$,  ただし$ {\\bf z}^{(l)} = \\mu + \\sigma \\odot \\epsilon^{(l)}, \\epsilon^{(l)}\\sim N(0,{\\bf I})$.\n",
    "\n",
    "  なおデコーダはベルヌーイ分布なので、右辺は次のように計算できます。\n",
    "  \n",
    "  $\\frac{1}{L}\\sum_{l=1}^L\\log p_\\theta({\\bf x}|{\\bf z}^{(l)})=\\frac{1}{L}\\sum_{l=1}^L \\sum_{i=1}^D x_i \\log \\lambda^{(l)}_i + (1-x_i)\\log (1-\\lambda^{(l)}_i)$,  ただし$\\lambda^{(l)}=f_{\\theta}({\\bf z}^{(l)})$.  \n",
    "  （実装内の`reconstruction`に対応）\n",
    "\n",
    "\n",
    "- また第2項については、次のように解析的に計算できます（ただし、$p_{\\theta}({\\bf z})={\\cal N}(0,{\\bf I})$とする）。\n",
    "  $D_{KL}[q_{\\phi}({\\bf z}|{\\bf x})||p_{\\theta}({\\bf z})] = -\\frac{1}{2}\\sum_{j=1}^J(1+\\log((\\sigma_j)^2)-(\\mu_j)^2-(\\sigma_j)^2)$  \n",
    "  （実装内の`KL`に対応）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "z_dim = 10\n",
    "\n",
    "def tf_log(x):\n",
    "    return tf.log(tf.clip_by_value(x, 1e-10, x))\n",
    "\n",
    "def encoder(x):\n",
    "    with tf.variable_scope('Encoder', reuse=tf.AUTO_REUSE):\n",
    "        h1 = tf.layers.Dense(units=200, activation=tf.nn.relu)(x)\n",
    "        h2 = tf.layers.Dense(units=200, activation=tf.nn.relu)(h1)\n",
    "        mean = tf.layers.Dense(units=z_dim)(h2)\n",
    "        var = tf.layers.Dense(units=z_dim, activation=tf.nn.softplus)(h2)\n",
    "    return mean, var\n",
    "\n",
    "def sampling_z(mean, var):\n",
    "    epsilon = tf.random_normal(shape=tf.shape(mean))\n",
    "    z = mean + tf.sqrt(var) * epsilon\n",
    "    return z\n",
    "\n",
    "def decoder(z):\n",
    "    with tf.variable_scope('Decoder', reuse=tf.AUTO_REUSE):\n",
    "        h3 = tf.layers.Dense(units=200, activation=tf.nn.relu)(z)\n",
    "        h4 = tf.layers.Dense(units=200, activation=tf.nn.relu)(h3)\n",
    "        y = tf.layers.Dense(units=784, activation=tf.nn.sigmoid)(h4)\n",
    "    return y\n",
    "\n",
    "def lower_bound(x):\n",
    "    #Encode\n",
    "    mean, var = encoder(x)\n",
    "    KL = -0.5 * tf.reduce_mean(tf.reduce_sum(1 + tf_log(var) - mean**2 - var, axis=1))\n",
    "    \n",
    "    #Z\n",
    "    z = sampling_z(mean, var)\n",
    "    \n",
    "    #Decode\n",
    "    y = decoder(z)\n",
    "    reconstruction = tf.reduce_mean(tf.reduce_sum(x * tf_log(y) + (1 - x) * tf_log(1 - y), axis=1))\n",
    "    \n",
    "    lower_bound = [-KL, reconstruction]\n",
    "    \n",
    "    return lower_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. パラメータの更新設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "lower_bound = lower_bound(x)\n",
    "\n",
    "cost = -tf.reduce_sum(lower_bound) # 下界を最大化するため、マイナスをとる\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "valid = tf.reduce_sum(lower_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size =100\n",
    "\n",
    "n_batches = x_train.shape[0] // batch_size\n",
    "n_epochs = 15\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "for epoch in range(n_epochs):\n",
    "    rng.shuffle(x_train)\n",
    "    lower_bound_all = []\n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        _, lowerbound = sess.run([train, lower_bound], feed_dict={x: x_train[start:end]})\n",
    "        lower_bound_all.append(lowerbound)\n",
    "    lower_bound_all = np.mean(lower_bound_all, axis=0)\n",
    "    lower_bound_valid = sess.run(valid, feed_dict={x: x_valid[0:100]})\n",
    "    print('EPOCH:%d, Train Lower Bound:%lf, (%lf, %lf), Valid Lower Bound:%lf' %\n",
    "          (epoch+1, np.sum(lower_bound_all), lower_bound_all[0], lower_bound_all[1], lower_bound_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 再構成画像の可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "sample_z_func = encoder(x) # mean, var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.placeholder(tf.float32, [None, z_dim])\n",
    "sample_x_func = decoder(z) # mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess(x):\n",
    "    _x = x.reshape(x.shape[0], 28, 28)\n",
    "    return 1 - _x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "_sample_x = deprocess(x_train[:n_samples])\n",
    "\n",
    "for j, _x in enumerate(_sample_x):\n",
    "    ax = fig.add_subplot(10, 10, j+1, xticks=[], yticks=[])\n",
    "    ax.imshow(_x, 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Reconstruction image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode\n",
    "mean, var = sess.run(sample_z_func, feed_dict={x: x_train[:n_samples]})\n",
    "sample_z = mean\n",
    "\n",
    "# Decode\n",
    "sample_x = sess.run(sample_x_func, feed_dict={z: sample_z})\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "_sample_x = deprocess(sample_x)\n",
    "\n",
    "for j, _x in enumerate(_sample_x):\n",
    "    ax = fig.add_subplot(10, 10, j+1, xticks=[], yticks=[])\n",
    "    ax.imshow(_x, 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 潜在変数からランダムサンプリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- z_dimを変更したときのサンプルを比較しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_z = np.random.standard_normal((n_samples, z_dim)).astype('float32')\n",
    "sample_z = sess.run(sample_x_func, feed_dict={z: sample_z})\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "_sample_x = deprocess(sample_z)\n",
    "\n",
    "for j, _x in enumerate(_sample_x):\n",
    "    ax = fig.add_subplot(10, 10, j+1, xticks=[], yticks=[])\n",
    "    ax.imshow(_x, 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 潜在空間の多様体の可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- データ間を遷移して、潜在空間で多様体構造が学習できていることを確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source\n",
    "x_0 = x_train[:1]\n",
    "\n",
    "# Target\n",
    "x_1 = x_train[1:2]\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax_0 = fig.add_subplot(1, 2, 1, xticks=[], yticks=[])\n",
    "ax_0.set_title('Source image')\n",
    "ax_0.imshow(deprocess(x_0)[0], 'gray')\n",
    "\n",
    "ax_1 = fig.add_subplot(1, 2, 2, xticks=[], yticks=[])\n",
    "ax_1.set_title('Target image')\n",
    "ax_1.imshow(deprocess(x_1)[0], 'gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 潜在空間に写像\n",
    "sample_z_0, _ = sess.run(sample_z_func, feed_dict={x: x_0})\n",
    "sample_z_1, _ = sess.run(sample_z_func, feed_dict={x: x_1})\n",
    "\n",
    "move = sample_z_1 - sample_z_0\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i, j in enumerate(np.linspace(0, 1, 10)):\n",
    "    # 線形補間\n",
    "    _z = sample_z_0 + j*move\n",
    "    sample_x = sess.run(sample_x_func, feed_dict={z: _z})\n",
    "\n",
    "    ax = fig.add_subplot(1, 10, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(deprocess(sample_x)[0], 'gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "目次",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "609px",
    "left": "385px",
    "top": "429px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
